{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "SUCCESS: Model built in 19.998 seconds\n",
      "SUCCESS: Images processed in 25.593 seconds\n",
      "SUCCESS: Total time spent = 45.748 seconds\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Original Author: Amit Kumar Mondal\n",
    "# Modified: Habib Sabiu\n",
    "# Date: September 4, 2017\n",
    "#\n",
    "# Description: A Spark application to cluster still camera images. The script read\n",
    "#              images data from HDFS and writes it's output to HDFS. The output is a\n",
    "#              text file containing image name and the cluster to which it belongs.\n",
    "#\n",
    "# Usage: spark-submit --master [spark master] [file name] [input path] [output_path] [job name]\n",
    "#        [spark master] = Can be Spark's Standalone, Mesos, or YARN\n",
    "#        To run on:-\n",
    "#                 Standalone: spark://discus-p2irc-master:7077\n",
    "#                 Mesos: mesos://discus-p2irc-master:5050\n",
    "#                 YARN: yarn\n",
    "#        [file name]   = Full path to the python script (../imageClustering.py)\n",
    "#        [input_path]  = Full HDFS path to input images\n",
    "#        [output_path] = Full HDFS path to save results. Please note that all contents of this\n",
    "#                        folder will be deleted if it already exist\n",
    "#        [job_name]    = A nice name for the job. This will be displayed on the web UI\n",
    "#\n",
    "# Example usage: spark-submit --master spark://discus-p2irc-master:7077 imageClustering.py \\\n",
    "#                hdfs://discus-p2irc-master:54310/user/hduser/habib/still_camera_images/ \\\n",
    "#                hdfs://discus-p2irc-master:54310/user/hduser/habib/flower_counter_output/ imageClustering\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import pyspark\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "\n",
    "from skimage import *\n",
    "from time import time\n",
    "from PIL import ImageFile\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from io import StringIO, BytesIO\n",
    "from scipy.spatial import distance\n",
    "from pyspark.mllib.clustering import KMeans, KMeansModel\n",
    "\n",
    "    \n",
    "def images_to_descriptors(rawdata):\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "    try:\n",
    "        fname = rawdata[0]\n",
    "        #imgbytes = np.array(io.imread(StringIO(rawdata[1]))) \n",
    "        imgbytes = np.array(io.imread(BytesIO(rawdata[1]))) \n",
    "        extractor = cv2.xfeatures2d.SIFT_create()\n",
    "        kp, descriptors = extractor.detectAndCompute(img_as_ubyte(imgbytes), None)\n",
    "        return [fname, descriptors]\n",
    "\n",
    "    except (ValueError, IOError, SyntaxError) as e:\n",
    "        pass\n",
    "\n",
    "\n",
    "def assign_pooling(data):\n",
    "\n",
    "    image_name, feature_matrix = data[0]\n",
    "    clusterCenters = data[1]\n",
    "\n",
    "    feature_matrix = np.array(feature_matrix)\n",
    "\n",
    "    model = KMeansModel(clusterCenters)\n",
    "    bow = np.zeros(len(clusterCenters))\n",
    "\n",
    "    for x in feature_matrix:\n",
    "        k = model.predict(x)\n",
    "        dist = distance.euclidean(clusterCenters[k], x)\n",
    "        bow[k] = max(bow[k], dist)\n",
    "\n",
    "    clusters = bow.tolist()\n",
    "    group = clusters.index(min(clusters)) + 1\n",
    "    return [image_name, group]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    application_start_time =  time()\n",
    "\n",
    "    \n",
    "    input_path = \"file:///Users/habib/Desktop/still_images_small/\"\n",
    "    output_path = \"file:///Users/habib/Desktop/outputs/\"\n",
    "    job_name = \"imageClustering\"\n",
    "    \n",
    "    import shutil\n",
    "    if os.path.exists(output_path[7:]):\n",
    "        shutil.rmtree(output_path[7:])\n",
    "        \n",
    "       \n",
    "    #input_path = sys.argv[1]\n",
    "    #output_path = sys.argv[2]\n",
    "    #job_name = sys.argv[3]\n",
    "    \n",
    "    #subprocess.call([\"hadoop\", \"fs\", \"-rm\", \"-r\", output_path])\n",
    "\n",
    "    sc = SparkContext(appName = job_name)\n",
    "\n",
    "    build_start_time = time()\n",
    "\n",
    "    images_rdd = sc.binaryFiles(input_path) \\\n",
    "        .map(images_to_descriptors) \\\n",
    "        .filter(lambda x: x[1].all() != None) \\\n",
    "        .map(lambda x: (x[0], x[1])) \n",
    "     \n",
    "    features = images_rdd.flatMap(lambda x: x[1])      \n",
    "\n",
    "    model = KMeans.train(features, 3, maxIterations=5, initializationMode=\"random\")\n",
    "    clusterCenters = model.clusterCenters\n",
    "\n",
    "    build_end_time = time() - build_start_time\n",
    "    \n",
    "    processing_start_time = time()\n",
    "\n",
    "    data_to_cluster = images_rdd.map(lambda x: [x, clusterCenters])\n",
    "\n",
    "    features_bow = data_to_cluster.map(assign_pooling)\n",
    "    features_bow.coalesce(1, shuffle=True).saveAsTextFile(output_path)\n",
    "\n",
    "        \n",
    "    processing_end_time = time() - processing_start_time\n",
    "    application_end_time = time() - application_start_time\n",
    "   \n",
    "    sc.stop()\n",
    "\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(\"SUCCESS: Model built in {} seconds\".format(round(build_end_time, 3)))\n",
    "    print(\"SUCCESS: Images processed in {} seconds\".format(round(processing_end_time, 3)))\n",
    "    print(\"SUCCESS: Total time spent = {} seconds\".format(round(application_end_time, 3)))\n",
    "    print(\"---------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "SUCCESS: Images read from HDFS in 1.637 seconds\n",
      "SUCCESS: Images processed in 234.653 seconds\n",
      "SUCCESS: Total time spent = 236.35 seconds\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Original Author: Keenan\n",
    "# Author: Habib Sabiu\n",
    "# Date: August 24, 2017\n",
    "#\n",
    "# Description: A Spark application to register drone images. Images should be in\n",
    "#              in a group of 5 chennels. For example, IMG_OOO1 group should have\n",
    "#              5 images representing various chennels e.g IMG_OOO1_1.png to IMG_OOO1_5.png.\n",
    "#              The output is a set of 5 registered images for each input group, and RGB of the\n",
    "#              location, croped version of the RGB, and an NDVI.\n",
    "#\n",
    "# Usage: spark-submit --master [spark master] [file name] [input path] [output_path] [job name]\n",
    "#        [spark master] = Can be Spark's Standalone, Mesos, or YARN\n",
    "#        To run on:-\n",
    "#                 Standalone: spark://discus-p2irc-master:7077\n",
    "#                 Mesos: mesos://discus-p2irc-master:5050\n",
    "#                 YARN: yarn\n",
    "#        [file name]   = Full path to the python script (../imageRegistration.py)\n",
    "#        [input_path]  = Full HDFS path to input images\n",
    "#        [output_path] = A network directory such as NFS3 that is accessible on all the worker nodes\n",
    "#        [job_name]    = A nice name for the job. This will be displayed on the web UI\n",
    "#\n",
    "# Example usage: spark-submit --master spark://discus-p2irc-master:7077 imageRegistration.py \\\n",
    "#                hdfs://discus-p2irc-master:54310/user/hduser/habib/drone_images_png/ \\\n",
    "#                /data/mounted_hdfs_path/user/hduser/habib/registered_images_output/ imageRegistration\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import math\n",
    "import string\n",
    "import random\n",
    "import pyspark\n",
    "import os.path\n",
    "import warnings\n",
    "import argparse\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "\n",
    "from time import time\n",
    "from operator import add\n",
    "from io import StringIO, BytesIO\n",
    "from skimage import img_as_ubyte\n",
    "from pyspark import SparkContext\n",
    "from PIL import Image, ImageFile\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# Set numpy array to print all it values instead of 3 dots in the middle\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "# Ignore all user warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Ignore divide by zero warning\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "\n",
    "def find_keypoints_and_features(image):\n",
    "\n",
    "    # Check that image is not invalid\n",
    "    if image is None:\n",
    "        raise TypeError(\"Invalid image in find_keypoints_and_features\")\n",
    "\n",
    "    descriptor = cv2.xfeatures2d.SIFT_create(nfeatures=100000)\n",
    "\n",
    "    #if fails means can't find similarities between two images\n",
    "    (key_points, features) = descriptor.detectAndCompute(image, None)\n",
    "\n",
    "    # IF YOU HAVE CV2 VERSION 2 USE THIS STUFF, INSTEAD OF THE ABOVE TWO LINES\n",
    "    # turn the image into greyscale to work with\n",
    "\n",
    "    #grey = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    #detector = cv2.FeatureDetector_create(\"SURF\")\n",
    "    #key_points = detector.detect(grey)\n",
    "    #extractor = cv2.DescriptorExtractor_create(\"SURF\")\n",
    "    #(key_points, features) = extractor.compute(grey, key_points)\n",
    "\n",
    "    # Convert key_points from KeyPoint objects to numpy arrays\n",
    "    key_points = np.float32([key_point.pt for key_point in key_points])\n",
    "    return (key_points, features)\n",
    "\n",
    "def match_key_points(right_key_points, left_key_points, right_features, left_features, ratio, reproj_thresh):\n",
    "\n",
    "    # A cv2 class that matches keypoint descriptors\n",
    "    # FLANN is a much faster method for large datasets, so it may be a good\n",
    "    # idea to switch to that. However it is a very different code set up\n",
    "    # that uses a couple dictionaries, so there's a bit that'll have to\n",
    "    # change\n",
    "    matcher = cv2.DescriptorMatcher_create(\"BruteForce\")\n",
    "    # knnMatch makes a whole bunch of matches (as a DMatch class)\n",
    "    # The k stands for how large the tuple will be (because that's\n",
    "    # basically what DMatches are)\n",
    "    # i picked two because straight lines\n",
    "    raw_matches = matcher.knnMatch(right_features, left_features, 2)\n",
    "\n",
    "    # Turns the raw_matches into tuples we can work with, while also\n",
    "    # filtering out matches that occurred on the outside edges of the\n",
    "    # pictures where matches really shouldn't have occurred\n",
    "    # Is equivalent to the following for loop\n",
    "    #        matches = []\n",
    "    #        for m in raw_matches:\n",
    "    #            if len(m) == 2 and m[0].distance < m[1].distance * ratio:\n",
    "    #                matches.append((m[0].trainIdx, m[0].queryIdx))\n",
    "    matches = [(m[0].trainIdx, m[0].queryIdx) for m in raw_matches if len(m) == 2 and m[0].distance < m[1].distance * ratio]\n",
    "\n",
    "    # Converts the tuples into a numpy array (for working with the\n",
    "    # homograph), while also splitting up the right and left points\n",
    "    # We are making a homograph of the matches to apply a ratio test, and\n",
    "    # determine which of the matches are of a high quality. Typical ratio\n",
    "    # values are between 0.7 and 0.8\n",
    "    # Computing a homography requires at least 4 matches\n",
    "    if len(matches) > 4:\n",
    "        # Split right and left into numphy arrays\n",
    "        src_pts = np.float32([right_key_points[i] for (_, i) in matches])\n",
    "        dst_pts = np.float32([left_key_points[i] for (i, _) in matches])\n",
    "\n",
    "        # Use the cv2 to actually connect the dots between the two pictures\n",
    "        (H, status) = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, reproj_thresh)\n",
    "\n",
    "        src_t = np.transpose(src_pts)\n",
    "        dst_t = np.transpose(dst_pts)\n",
    "        back_proj_error = 0\n",
    "        inlier_count = 0\n",
    "\n",
    "        for i in range(0, src_t.shape[1]):\n",
    "            x_i = src_t[0][i]\n",
    "            y_i = src_t[1][i]\n",
    "            x_p = dst_t[0][i]\n",
    "            y_p = dst_t[1][i]\n",
    "            num1 = (H[0][0] * x_i + H[0][1] * y_i + H[0][2])\n",
    "            num2 = (H[1][0] * x_i + H[1][1] * y_i + H[1][2])\n",
    "            dnm = (H[2][0] * x_i + H[2][1] * y_i + H[2][2])\n",
    "\n",
    "            tmp = (x_p - (num1 / dnm))**2 + (y_p - (num2 / dnm))**2\n",
    "            if status[i] == 1:\n",
    "                back_proj_error += tmp\n",
    "                inlier_count += 1\n",
    "\n",
    "        return (matches, H, status, back_proj_error, inlier_count)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def register_channels(C, idx=0, ratio=.75, reproj_thresh=4):\n",
    "\n",
    "    # Check that the images in C are good images and not empty\n",
    "    if C is None:\n",
    "        raise TypeError(\"Invalid image set in register_channels\")\n",
    "    for i in C:\n",
    "        if len(i.shape) > 2:\n",
    "            raise TypeError(\"Images have greater depth than 1!\")\n",
    "\n",
    "    # Compute SIFT features for each channel.\n",
    "    # Channel images are converted to unsigned byte.  All proper scaling\n",
    "    # is done by image_as_ubyte regardless of dtype of the input images.\n",
    "    keypoints_and_features = [find_keypoints_and_features(img_as_ubyte(chan)) for chan in C]\n",
    "\n",
    "    # Generate list of indices excluding the target channel index.\n",
    "    channels_to_register = list(range(len(C)))\n",
    "    del channels_to_register[idx]\n",
    "\n",
    "    # Generate keypoint matches between each channel to be registered\n",
    "    # and the target image.\n",
    "    matched_key_points = [match_key_points(keypoints_and_features[i][0], keypoints_and_features[idx][0], keypoints_and_features[i][1],\n",
    "                                           keypoints_and_features[idx][1], ratio=ratio, reproj_thresh=reproj_thresh) for i in channels_to_register]\n",
    "\n",
    "    # extract the homography matrices from 'matched_key_points'.\n",
    "    H = [x[1] for x in matched_key_points]\n",
    "    BPError = [x[3] for x in matched_key_points]\n",
    "    Inliers = [x[4] for x in matched_key_points]\n",
    "    # Add the identity matrix for the target channel.\n",
    "    H.insert(idx, np.identity(3))\n",
    "    return H, BPError, Inliers\n",
    "\n",
    "def warp_image(I, H):\n",
    "    return cv2.warpPerspective(I, H, (I.shape[1], I.shape[0]))\n",
    "\n",
    "def transform_channels(C, H):\n",
    "    return [warp_image(C[i], H[i]) for i in range(len(C))]\n",
    "\n",
    "def decompose_homography(H):\n",
    "\n",
    "    if H is None:\n",
    "        raise TypeError(\"Invalid homogrpahy input in decompose_homogrphy\")\n",
    "    if H.shape != (3, 3):\n",
    "        raise TypeError(\"Invalid homogrpahy shape in decompose_homogrphy\")\n",
    "\n",
    "    a = H[0, 0]\n",
    "    b = H[0, 1]\n",
    "    c = H[0, 2]\n",
    "    d = H[1, 0]\n",
    "    e = H[1, 1]\n",
    "    f = H[1, 2]\n",
    "\n",
    "    p = math.sqrt(a * a + b * b)\n",
    "    r = (a * e - b * d) / (p)\n",
    "    q = (a * d + b * e) / (a * e - b * d)\n",
    "\n",
    "    translation = (c, f)\n",
    "    scale = (p, r)\n",
    "    shear = q\n",
    "    theta = math.atan2(b, a)\n",
    "\n",
    "    return (translation, theta, scale, shear)\n",
    "\n",
    "def register_group(images_group):\n",
    "\n",
    "    images_key = images_group[0]\n",
    "    images_values = images_group[1]\n",
    "    images_values = sorted(zip(images_values[0::2], images_values[1::2]))\n",
    "\n",
    "    keys = [x[0] for x in images_values]\n",
    "    values = [x[1] for x in images_values]\n",
    "\n",
    "    # Get the images and store them in an array, then calculate their homographies and transform the images.\n",
    "    # H, Back-proj-error and the inlier points are all calculated\n",
    "    C = np.array(values, dtype=float)  / 65535\n",
    "\n",
    "    H, BPError, Inliers = register_channels(C)\n",
    "    # Add a 0 to the start of the list of back projection errors, since the\n",
    "    # first image always has a BPError of 0 (This is for later where we need to print the BPErrors)\n",
    "\n",
    "    BPError.insert(0, 0)\n",
    "    T = transform_channels(C, H)\n",
    "\n",
    "    # Decompose the homogrpahy and calculate the bounding box of the good data, where all 5 channels are present\n",
    "    max_x = []\n",
    "    max_y = []\n",
    "    max_theta = []\n",
    "\n",
    "    for j in H:\n",
    "        max_x.append(abs(decompose_homography(j)[0][0]))\n",
    "        max_y.append(abs(decompose_homography(j)[0][1]))\n",
    "        max_theta.append(abs(decompose_homography(j)[1]))\n",
    "\n",
    "    rot = math.ceil(math.sin(max(max_theta)) * C[0].shape[1])\n",
    "    crop_x = math.ceil(max(max_x))\n",
    "    crop_y = math.ceil(max(max_y))\n",
    "\n",
    "    border_x = (crop_x + rot, C[0].shape[1] - crop_x - rot)\n",
    "    border_y = (crop_y + rot, C[0].shape[0] - crop_y - rot)\n",
    "\n",
    "    # Loop through each subset of images and re-save them now that they are registered\n",
    "    for j in range(len(T)):\n",
    "\n",
    "        output_image_path = os.path.abspath(os.path.join(OUTPUT_FILE_PATH, \"IMG_\" + images_key + \"_\" + str(j + 1) + OUTPUT_FILE_TYPE))\n",
    "\n",
    "        # Different ways to save the numpy array as image\n",
    "        #io.imsave(output_image_path, T[j])\n",
    "\n",
    "        # Here the array is first converted into a cv2 image and then saved\n",
    "        cv_image = np.array(T[j]*255)\n",
    "        cv2.imwrite(output_image_path, cv_image)\n",
    "\n",
    "        # Here the array is first converted into a PIL image and then saved\n",
    "        #im = Image.fromarray(T[j])\n",
    "        #im.save(output_image_path)\n",
    "\n",
    "    # Create and save the RGB image\n",
    "    rgb = np.dstack([T[2], T[1], T[0]])\n",
    "    output_rgb_path = os.path.abspath(os.path.join(OUTPUT_PROCESSED_PATH, \"IMG_\" + images_key + \"_RGB\" + OUTPUT_FILE_TYPE))\n",
    "\n",
    "    #io.imsave(output_rgb_path, rgb)\n",
    "\n",
    "    cv_image = np.array(rgb*255)\n",
    "    cv2.imwrite(output_rgb_path, cv_image)\n",
    "\n",
    "    #im = Image.fromarray(rgb)\n",
    "    #im.save(output_rgb_path)\n",
    "\n",
    "    # Crop images\n",
    "    crop_img = np.dstack([T[2], T[1], T[0]])\n",
    "    crop_img = crop_img[int(border_y[0]):int(border_y[1]), int(border_x[0]):int(border_x[1])]\n",
    "    output_crop_path = os.path.abspath(os.path.join(OUTPUT_PROCESSED_PATH, \"IMG_\" + images_key  + \"_RGB_CROPPED\" + OUTPUT_FILE_TYPE))\n",
    "\n",
    "    #io.imsave(output_crop_path, crop_img)\n",
    "\n",
    "    cv_image = np.array(crop_img*255)\n",
    "    cv2.imwrite(output_crop_path, cv_image)\n",
    "\n",
    "    #im = Image.fromarray(crop_img)\n",
    "    #im.save(output_crop_path)\n",
    "\n",
    "    # Create and save the NDVI image\n",
    "    num = np.subtract(T[3], T[2])\n",
    "    dnm = np.add(T[3], T[2])\n",
    "\n",
    "    ndvi_img = np.divide(num, dnm)\n",
    "\n",
    "    original_ndvi = ndvi_img\n",
    "\n",
    "    output_ndvi_path = os.path.abspath(os.path.join(OUTPUT_PROCESSED_PATH, \"IMG_\" + images_key  + \"_NDVI\" + OUTPUT_FILE_TYPE))\n",
    "\n",
    "    #io.imsave(output_ndvi_path, original_ndvi)\n",
    "\n",
    "    cv_image = np.array(original_ndvi*255)\n",
    "    cv2.imwrite(output_ndvi_path, cv_image)\n",
    "\n",
    "    #im = Image.fromarray(original_ndvi)\n",
    "    #im.save(output_ndvi_path)\n",
    "\n",
    "def read_images(image_rawdata):\n",
    "    #return image_rawdata[0], np.array(io.imread((StringIO(image_rawdata[1])), as_grey=True) / 65535)\n",
    "    return image_rawdata[0], np.array(io.imread(BytesIO(image_rawdata[1]), as_grey=True))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    application_start_time =  time()\n",
    "    \n",
    "    \n",
    "    input_path = \"file:///Users/habib/Desktop/drone_images_small/\"\n",
    "    output_root_path = \"/Users/habib/Desktop/outputs/\"\n",
    "    job_name = \"imageRegistration\"\n",
    "\n",
    "\n",
    "    #input_path = sys.argv[1]\n",
    "    #output_root_path = sys.argv[2]\n",
    "    #job_name = sys.argv[3]\n",
    "    \n",
    "    OUTPUT_FILE_TYPE = \".png\"\n",
    "    # Directory to store registered images\n",
    "    OUTPUT_FILE_PATH = output_root_path\n",
    "    # Directory to store processed registered images\n",
    "    OUTPUT_PROCESSED_PATH = output_root_path + \"/processed/\"\n",
    "    \n",
    "    \n",
    "    # Set spark configurations\n",
    "    sc = SparkContext(appName = job_name)\n",
    "\n",
    "    reading_start_time = time()\n",
    "\n",
    "    # When reading from local file system\n",
    "    #images_rdd = sc.binaryFiles('file:///sparkdata/registration_images')\n",
    "    \n",
    "    # When reading from HDFS\n",
    "    images_rdd = sc.binaryFiles(input_path)\n",
    "    \n",
    "    index = images_rdd.first()[0].find(\"IMG_\")+4\n",
    "\n",
    "    images_group_rdd = images_rdd.map(read_images) \\\n",
    "        .map(lambda rawdata: (rawdata[0][index:rawdata[0].rfind('_')], (rawdata[0][index:], rawdata[1]))) \\\n",
    "        .reduceByKey(lambda first_image, second_image: (first_image + second_image))\n",
    "\n",
    "    reading_end_time = time() - reading_start_time\n",
    "\n",
    "    processing_start_time = time()\n",
    "\n",
    "    images_group_rdd.foreach(register_group)\n",
    "\n",
    "    processing_end_time = time() - processing_start_time\n",
    "\n",
    "    application_end_time = time() - application_start_time\n",
    "    \n",
    "    sc.stop()\n",
    "    \n",
    "    print(\"------------------------------------------------\")\n",
    "    print(\"SUCCESS: Images read from HDFS in {} seconds\".format(round(reading_end_time, 3)))\n",
    "    print(\"SUCCESS: Images processed in {} seconds\".format(round(processing_end_time, 3)))\n",
    "    print(\"SUCCESS: Total time spent = {} seconds\".format(round(application_end_time, 3)))\n",
    "    print(\"------------------------------------------------\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "SUCCESS: Images procesed in 31.924 seconds\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Original Author: Javier Garcia\n",
    "# Modified: Habib Sabiu\n",
    "# Date: August 24, 2017\n",
    "#\n",
    "# Description: An application to detect and count canola flowers from still camera images.\n",
    "#              The script reads input images from a local directory. \n",
    "#\n",
    "# Example usage: python imageFlowerCounterNewSquencial.py\n",
    "#\n",
    "# Note: Make sure to update the \"imagesBasePath\" with the path to the directory where the\n",
    "#       input images can be found\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import glob\n",
    "#import pyspark\n",
    "import operator\n",
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "import skimage.io as io\n",
    "from enum import Enum\n",
    "from time import time\n",
    "from io import StringIO, BytesIO\n",
    "from PIL import Image, ImageFile\n",
    "from skimage.feature import blob_doh\n",
    "#from pyspark import SparkConf, SparkContext\n",
    "from sklearn.cluster import KMeans as skKMeans\n",
    "\n",
    "\n",
    "\n",
    "class CanolaObject:\n",
    "    def __str__(self):\n",
    "        strObject = ''\n",
    "        for k, v in self.__dict__.items():\n",
    "            strObject += '{} : {}\\n'.format(k, v)\n",
    "        return strObject\n",
    "\n",
    "\n",
    "class CanolaPlotRegionObject(CanolaObject):\n",
    "    def __init__(self):\n",
    "        self.__id = None\n",
    "        self.__plot = None\n",
    "        self.__year = None\n",
    "        self.__corners = None\n",
    "        self.__allocatedPlotMask = None\n",
    "        self.__allocatedRegionMask = None\n",
    "\n",
    "    def setPlot(self, plot):\n",
    "        assert self.__plot is None\n",
    "        self.__plot = plot\n",
    "\n",
    "    def setYear(self, year):\n",
    "        assert self.__year is None\n",
    "        self.__year = year\n",
    "\n",
    "    def setCorners(self, corners):\n",
    "        assert self.__corners is None\n",
    "        self.__corners = corners\n",
    "\n",
    "    def setId(self, id):\n",
    "        assert self.__id is None\n",
    "        self.__id = id\n",
    "\n",
    "    def setPlotMask(self, plotMask):\n",
    "        assert self.__allocatedPlotMask is None\n",
    "        self.__allocatedPlotMask = plotMask\n",
    "\n",
    "    def setRegionMask(self, regionMask):\n",
    "        assert self.__allocatedRegionMask is None\n",
    "        self.__allocatedRegionMask = regionMask\n",
    "\n",
    "\n",
    "    def getPlot(self):\n",
    "        return self.__plot\n",
    "\n",
    "    def getYear(self):\n",
    "        return self.__year\n",
    "\n",
    "    def getCorners(self):\n",
    "        return self.__corners\n",
    "\n",
    "    def getId(self):\n",
    "        return self.__id\n",
    "\n",
    "    def getPlotMask(self):\n",
    "        return self.__allocatedPlotMask\n",
    "\n",
    "    def getRegionMask(self):\n",
    "        return self.__allocatedRegionMask\n",
    "\n",
    "\n",
    "class CanolaImageClassifierObject(CanolaObject):\n",
    "    def __init__(self):\n",
    "        self.__id = None\n",
    "        self.__imageId = None\n",
    "        self.__cluster = None\n",
    "        self.__numberOfYellowPixels = None\n",
    "        self.__corrupted = False\n",
    "        self.__regionObject = None\n",
    "\n",
    "    def setCluster(self, cluster):\n",
    "        assert self.__cluster is None\n",
    "        self.__cluster = cluster\n",
    "\n",
    "    def setRegionObject(self, regionObject):\n",
    "        assert self.__regionObject is None\n",
    "        self.__regionObject = regionObject\n",
    "\n",
    "    def setNumberOfYellowPixels(self, numberOfYellowPixels):\n",
    "        assert self.__numberOfYellowPixels is None\n",
    "        self.__numberOfYellowPixels = numberOfYellowPixels\n",
    "\n",
    "    def setId(self, id):\n",
    "        assert self.__id is None\n",
    "        self.__id = id\n",
    "\n",
    "    def setImageId(self, imageId):\n",
    "        assert self.__imageId is None\n",
    "        self.__imageId = imageId\n",
    "\n",
    "    def flagCorrupted(self):\n",
    "        self.__corrupted = True\n",
    "\n",
    "\n",
    "    def getCluster(self):\n",
    "        return self.__cluster\n",
    "\n",
    "    def getRegionObject(self):\n",
    "        return self.__regionObject\n",
    "\n",
    "    def getNumberOfYellowPixels(self):\n",
    "        return self.__numberOfYellowPixels\n",
    "\n",
    "    def getId(self):\n",
    "        return self.__id\n",
    "\n",
    "    def getImageId(self):\n",
    "        return self.__imageId\n",
    "\n",
    "    def isCorrupted(self):\n",
    "        return self.__corrupted\n",
    "\n",
    "\n",
    "class HistogramObject(CanolaObject):\n",
    "    def __init__(self):\n",
    "        self.__id = None\n",
    "        self.__imageId = None\n",
    "        self.__histogramB = None\n",
    "        self.__histogramG = None\n",
    "        self.__histogramBShift = None\n",
    "        self.__regionObject = None\n",
    "\n",
    "    def setId(self, id):\n",
    "        assert self.__id is None\n",
    "        self.__id = id\n",
    "\n",
    "    def setImageId(self, imageId):\n",
    "        assert self.__imageId is None\n",
    "        self.__imageId = imageId\n",
    "\n",
    "    def setHistogramB(self, histogramB):\n",
    "        assert self.__histogramB is None\n",
    "        self.__histogramB = histogramB\n",
    "\n",
    "    def setHistogramG(self, histogramG):\n",
    "        assert self.__histogramG is None\n",
    "        self.__histogramG = histogramG\n",
    "\n",
    "    def setHistogramBShift(self, histogramBShift):\n",
    "        assert self.__histogramBShift is None\n",
    "        self.__histogramBShift = histogramBShift\n",
    "\n",
    "    def setRegionObject(self, regionObject):\n",
    "        assert self.__regionObject is None\n",
    "        self.__regionObject = regionObject\n",
    "\n",
    "\n",
    "    def getId(self):\n",
    "        return self.__id\n",
    "\n",
    "    def getImageId(self):\n",
    "        return self.__imageId\n",
    "\n",
    "    def getHistogramB(self):\n",
    "        return self.__histogramB\n",
    "\n",
    "    def getHistogramG(self):\n",
    "        return self.__histogramG\n",
    "\n",
    "    def getHistogramBShift(self):\n",
    "        return self.__histogramBShift\n",
    "\n",
    "    def getRegionObject(self):\n",
    "        return self.__regionObject\n",
    "\n",
    "\n",
    "class PipelineObject(CanolaObject):\n",
    "    def __init__(self, pipeline=None):\n",
    "        self.__id = None\n",
    "        self.__pipeline = pipeline\n",
    "\n",
    "    def setPipeline(self, pipeline):\n",
    "        assert self.__pipeline is None\n",
    "        self.__pipeline = pipeline\n",
    "\n",
    "    def setId(self, id):\n",
    "        assert self.__id is None\n",
    "        self.__id = id\n",
    "\n",
    "\n",
    "    def getPipeline(self):\n",
    "        return self.__pipeline\n",
    "\n",
    "    def getId(self):\n",
    "        return self.__id\n",
    "\n",
    "\n",
    "class FlowerCountObject(CanolaObject):\n",
    "    def __init__(self):\n",
    "        self.__id = None\n",
    "        self.__imageId = None\n",
    "        self.__blobs = None\n",
    "        self.__regionObject = None\n",
    "        self.__pipelineObject = PipelineObject(CanolaObject)\n",
    "\n",
    "    def setBlobs(self, blobs):\n",
    "        assert self.__blobs is None\n",
    "        self.__blobs = blobs\n",
    "\n",
    "    def setRegionObject(self, regionObject):\n",
    "        assert self.__regionObject is None\n",
    "        self.__regionObject = regionObject\n",
    "\n",
    "    def setId(self, id):\n",
    "        assert self.__id is None\n",
    "        self.__id = id\n",
    "\n",
    "    def setImageId(self, imageId):\n",
    "        assert self.__imageId is None\n",
    "        self.__imageId = imageId\n",
    "\n",
    "\n",
    "    def getPipelineObject(self):\n",
    "        return self.__pipelineObject\n",
    "\n",
    "    def getBlobs(self):\n",
    "        return self.__blobs\n",
    "\n",
    "    def getRegionObject(self):\n",
    "        return self.__regionObject\n",
    "\n",
    "    def getId(self):\n",
    "        return self.__id\n",
    "\n",
    "    def getImageId(self):\n",
    "        return self.__imageId\n",
    "\n",
    "\n",
    "class CanolaTimelapseImage(CanolaObject):\n",
    "    def __init__(self):\n",
    "        self.__id = None\n",
    "        self.__imageId = None\n",
    "        self.__path = None\n",
    "        self.__timestamp = None\n",
    "        self.__imageSize = None\n",
    "        self.__plot = None\n",
    "        self.__allocatedImageArray = None\n",
    "        self.__corrupted = False\n",
    "        self.__classifierObject = CanolaImageClassifierObject()\n",
    "        self.__histogramObject = HistogramObject()\n",
    "        self.__flowerCountObject = FlowerCountObject()\n",
    "\n",
    "    def readImage(self):\n",
    "        if self.__allocatedImageArray is None:\n",
    "            ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "            pil_image = Image.open(self.__path).convert('RGB')\n",
    "            open_cv_image = np.array(pil_image)\n",
    "            self.__allocatedImageArray = open_cv_image[:, :, ::-1].copy()\n",
    "        return self.__allocatedImageArray\n",
    "\n",
    "    def showDetectedBlobs(self):\n",
    "        blobs = self.__flowerCountObject.getBlobs()\n",
    "        assert blobs is not None\n",
    "        img = np.copy( self.readImage() )\n",
    "        for x, y, r in blobs:\n",
    "            cv2.circle(img,center=(int(y), int(x)),radius=int(r),color=(0, 255, 255),thickness=2)\n",
    "        cv2.imshow(\"{} {}\".format( self.__plot, self.__timestamp ),img )\n",
    "        cv2.waitKey( 0 )\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def getPlotMask(self):\n",
    "        regionObject = self.getRegionObject()\n",
    "        plotMask = regionObject.getPlotMask()\n",
    "\n",
    "        if plotMask is None:\n",
    "            regionObject.setPlotMask(Mask.generate(self.__imageSize,regionObject.getCorners()))\n",
    "        return regionObject.getPlotMask()\n",
    "\n",
    "    def getRegionMask(self):\n",
    "        regionObject = self.getRegionObject()\n",
    "        regionMask = regionObject.getRegionMask()\n",
    "        if regionMask is None:\n",
    "            regionManager = RegionManager()\n",
    "            regionObject.setRegionMask(regionManager.getRegionMask(self.__imageSize,regionObject.getCorners()))\n",
    "        return regionObject.getRegionMask()\n",
    "\n",
    "    # SETTERS\n",
    "\n",
    "    def setPath(self, path):\n",
    "        assert self.__path is None\n",
    "        self.__path = path\n",
    "\n",
    "    def setTimestamp(self, timestamp):\n",
    "        assert self.__timestamp is None\n",
    "        if isinstance( timestamp, str ):\n",
    "            timestamp = stringToDatetime( timestamp )\n",
    "        self.__timestamp = timestamp\n",
    "\n",
    "    def setImageId(self, imageId):\n",
    "        assert self.__imageId is None\n",
    "        self.__imageId = imageId\n",
    "        self.__classifierObject.setImageId( imageId )\n",
    "        self.__histogramObject.setImageId( imageId )\n",
    "        self.__flowerCountObject.setImageId( imageId )\n",
    "\n",
    "    def setImageSize(self, imageSize):\n",
    "        assert self.__imageSize is None\n",
    "        if isinstance( imageSize, str ):\n",
    "            imageSize = tuple([int(k) for k in imageSize.split('x')[::-1]])\n",
    "        self.__imageSize = imageSize\n",
    "\n",
    "    def setPlot(self, plot):\n",
    "        assert self.__plot is None\n",
    "        regionObject = self.getRegionObject()\n",
    "        if regionObject is not None:\n",
    "            regionPlot = regionObject.getPlot()\n",
    "            if regionPlot is not None:\n",
    "                assert plot == regionPlot\n",
    "        self.__plot = plot\n",
    "\n",
    "    def setId(self, id):\n",
    "        assert self.__id is None\n",
    "        self.__id = id\n",
    "\n",
    "    def setRegionObject(self, regionObject):\n",
    "        self.__classifierObject.setRegionObject( regionObject )\n",
    "        self.__histogramObject.setRegionObject( regionObject )\n",
    "        self.__flowerCountObject.setRegionObject( regionObject )\n",
    "\n",
    "\n",
    "    # GETTERS\n",
    "\n",
    "    def getPath(self):\n",
    "        return self.__path\n",
    "\n",
    "    def getTimestamp(self):\n",
    "        return self.__timestamp\n",
    "\n",
    "    def getImageId(self):\n",
    "        return self.__imageId\n",
    "\n",
    "    def getImageSize(self):\n",
    "        return self.__imageSize\n",
    "\n",
    "    def getPlot(self):\n",
    "        return self.__plot\n",
    "\n",
    "    def getRegionObject(self):\n",
    "        return self.__histogramObject.getRegionObject()\n",
    "\n",
    "    def getPipelineObject(self):\n",
    "        return self.__flowerCountObject.getPipelineObject()\n",
    "\n",
    "    def getClassifierObject(self):\n",
    "        return self.__classifierObject\n",
    "\n",
    "    def getHistogramObject(self):\n",
    "        return self.__histogramObject\n",
    "\n",
    "    def getFlowerCountObject(self):\n",
    "        return self.__flowerCountObject\n",
    "\n",
    "    def getId(self):\n",
    "        return self.__id\n",
    "\n",
    "    def isCorrupted(self):\n",
    "        return self.__classifierObject.isCorrupted()\n",
    "\n",
    "\n",
    "class ImageProcessingModule:\n",
    "\n",
    "    def processImage( self, imageArray, *argv ):\n",
    "        assert self._isValidImage(imageArray), self.__class__.__name__\n",
    "        return self._process( imageArray, *argv )\n",
    "\n",
    "    def getParamsFromCanolaTimelapseImage(self, canolaTimelapseImage):\n",
    "        return None\n",
    "\n",
    "    def _process( self, imageArray, *argv ):\n",
    "        pass\n",
    "\n",
    "    def _isValidImage(self, imageArray):\n",
    "        return isinstance( imageArray, np.ndarray ) and imageArray.dtype == np.uint8\n",
    "\n",
    "\n",
    "class ImageProcessingPipeline:\n",
    "    def __init__(self):\n",
    "        self.__modules = []\n",
    "\n",
    "    def addModule(self, moduleInstance):\n",
    "        assert isinstance( moduleInstance, ImageProcessingModule )\n",
    "        self.__modules.append( moduleInstance )\n",
    "\n",
    "    def run(self, canolaTimelapseImage):\n",
    "        res = canolaTimelapseImage.readImage()\n",
    "        for module in self.__modules:\n",
    "            res = module.processImage( res,module.getParamsFromCanolaTimelapseImage(canolaTimelapseImage ) )\n",
    "        return res\n",
    "\n",
    "    def __str__(self):\n",
    "        return ','.join([k.__class__.__name__ for k in self.__modules])\n",
    "\n",
    "\n",
    "class FlowerCountImageProcessor:\n",
    "    def run( self, canolaTimelapseImages ):\n",
    "\n",
    "        result = (self.runSingleImage(image) for image in canolaTimelapseImages)\n",
    "        result = dict( [k for k in result if k is not None] )\n",
    "        for img in canolaTimelapseImages:\n",
    "            path = img.getPath()\n",
    "            if path in result.keys():\n",
    "                img.getFlowerCountObject().setBlobs(result[img.getPath()])\n",
    "\n",
    "    def runSingleImage(self, canolaTimelapseImage):\n",
    "        blobs = canolaTimelapseImage.getFlowerCountObject().getBlobs()\n",
    "        if blobs is not None:\n",
    "            return (None, None)\n",
    "\n",
    "        flowerCountPipeline = ImageProcessingPipeline()\n",
    "        flowerCountPipeline.addModule(CIELabColorspaceModule())\n",
    "        flowerCountPipeline.addModule(SigmoidMapping())\n",
    "        flowerCountPipeline.addModule(BlobDetection())\n",
    "        \n",
    "        blobs = flowerCountPipeline.run( canolaTimelapseImage )\n",
    "\n",
    "        return (canolaTimelapseImage.getPath(),blobs)\n",
    "\n",
    "\n",
    "class Transformation3D(ImageProcessingModule):\n",
    "    def _isValidImage(self, imageArray):\n",
    "        return ImageProcessingModule._isValidImage(self, imageArray) and np.ndim( imageArray ) == 3\n",
    "\n",
    "\n",
    "class Transformation2D(ImageProcessingModule):\n",
    "    def _isValidImage(self, imageArray):\n",
    "        return ImageProcessingModule._isValidImage(self, imageArray) and np.ndim( imageArray ) == 2\n",
    "\n",
    "\n",
    "class CIELabColorspaceModule(Transformation3D):\n",
    "    def _process( self, imageArray, *argv ):\n",
    "        \"\"\"\n",
    "        Shift image from BGR to CIELab colorspace and return channel B\n",
    "        \"\"\"\n",
    "        colorspace = cv2.cvtColor( imageArray, cv2.COLOR_BGR2Lab )\n",
    "        return colorspace[:,:,2]\n",
    "\n",
    "\n",
    "class OtsuThreshold(Transformation2D):\n",
    "    def _process( self, imageArray, *argv ):\n",
    "        \"\"\"\n",
    "        Apply Otsu threshold. Output image has zero on pixels with value\n",
    "        lower than threshold, and their original value otherwise\n",
    "        \"\"\"\n",
    "        blur = cv2.GaussianBlur( imageArray, (5,5), 0 )\n",
    "        return cv2.threshold( blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU )\n",
    "\n",
    "\n",
    "class SigmoidMapping(Transformation2D):\n",
    "    def getParamsFromCanolaTimelapseImage(self, canolaTimelapseImage):\n",
    "        return canolaTimelapseImage.getHistogramObject().getHistogramBShift()\n",
    "\n",
    "    def _process( self, imageArray, *argv ):\n",
    "        \"\"\"\n",
    "        Map every pixel's intensity to an output value given by a sigmoid function.\n",
    "        f(x) = K / ( 1 + e^(t-d*x) )\n",
    "        \"\"\"\n",
    "        yellowThreshMapValue = 0.99\n",
    "        yellowThreshFromZero = 6\n",
    "        yellowThreshold = 155\n",
    "\n",
    "        hist_b_shift = argv[0]\n",
    "        imageArrayFloat = np.array( imageArray, dtype=np.float32 )\n",
    "        t_exp = (yellowThreshold + hist_b_shift - yellowThreshFromZero) % 256\n",
    "        k_exp = np.log(1 / yellowThreshMapValue - 1) / yellowThreshFromZero\n",
    "        imgAsFloat = 1 / (1 + np.exp(k_exp * (imageArrayFloat - t_exp)))\n",
    "        return ( imgAsFloat * 255 ).astype( np.uint8 )\n",
    "\n",
    "\n",
    "class IntensityMapping(Transformation2D):\n",
    "    def getParamsFromCanolaTimelapseImage(self, canolaTimelapseImage):\n",
    "        return canolaTimelapseImage.getHistogramObject().getHistogramBShift()\n",
    "\n",
    "    def _process( self, imageArray, *argv ):\n",
    "        \"\"\"\n",
    "        Perform mapping on grayscale channel to highlight flowers\n",
    "        \"\"\"\n",
    "        hist_b_shift = argv[0]\n",
    "        imageArrayFloat = np.array( imageArray, dtype=np.float )\n",
    "        threshold = ( self._params[\"flowerIntensityThreshold\"] + hist_b_shift ) % 256\n",
    "        imageArrayFloat = np.clip( imageArrayFloat, 0, threshold + 10 )\n",
    "        imageArrayFloat -= threshold - 8\n",
    "        imageArrayFloat /= threshold + 10\n",
    "        imageArrayFloat = np.clip( imageArrayFloat, 0, 1 )\n",
    "        return np.array( imageArrayFloat, dtype=np.uint8 )\n",
    "\n",
    "\n",
    "class BlobDetection(Transformation2D):\n",
    "    def getParamsFromCanolaTimelapseImage(self, canolaTimelapseImage):\n",
    "        return [canolaTimelapseImage.getPlotMask(),canolaTimelapseImage.getClassifierObject().getNumberOfYellowPixels()]\n",
    "\n",
    "    def _process( self, imageArray, *argv ):\n",
    "        \"\"\"\n",
    "        Count blobs\n",
    "        :param *argv: Mask\n",
    "        :return: List of tuples with (x, y, size) information of every blob detected\n",
    "        \"\"\"\n",
    "        mask = argv[0][0]\n",
    "        yellowPixels = argv[0][1]\n",
    "        if yellowPixels == 0:\n",
    "            return []\n",
    "        mask = mask > 0\n",
    "        maskedImage = np.copy( imageArray )\n",
    "        maskedImage[ mask == 0 ] = 0\n",
    "        blobs = blob_doh(maskedImage,max_sigma=8,min_sigma=3 )\n",
    "        return [[int(x), int(y), float(z)] for x, y, z in blobs]\n",
    "\n",
    "\n",
    "class ImageClassifier:\n",
    "    def classify( self, canolaTimelapseImages ):\n",
    "        kmeans = KMeans()\n",
    "        histogramManager = HistogramManager()\n",
    "        corruptedImagesDetector = CorruptedImagesDetector()\n",
    "        histogramManager.runImages( canolaTimelapseImages )        \n",
    "        corruptedImagesDetector.flagCorruptedImages(canolaTimelapseImages)\n",
    "        kmeans.clusterImages( canolaTimelapseImages )\n",
    "\n",
    "\n",
    "class KMeans:\n",
    "\n",
    "    def clusterImages( self, canolaTimelapseImages ):\n",
    "        nonCorruptedImages = [img for img in canolaTimelapseImages if not img.isCorrupted()]\n",
    "        if self.__isClusteringAlreadyDone( canolaTimelapseImages ):\n",
    "            return\n",
    "        fileToFlowerPixelsDict = self.__calculateNumberOfFlowerPixels(nonCorruptedImages)\n",
    "        numClusters = 4\n",
    "        kmeans_fwperc = self.__kmeans( fileToFlowerPixelsDict, nClusters=numClusters)\n",
    "        kmeans_copy = dict( (k, v) for k, v in fileToFlowerPixelsDict.items( ) if kmeans_fwperc[k] == 0 )\n",
    "        kmeans_fwperc_2 = self.__kmeans( kmeans_copy, nClusters=2 )\n",
    "        \n",
    "        # For every image originally on cluster 0, reassign to cluster 1 or keep on cluster 0 depending on the second\n",
    "        # K-means result\n",
    "        for img in canolaTimelapseImages:\n",
    "            classifierObject = img.getClassifierObject()\n",
    "            if kmeans_fwperc.__contains__( img ):\n",
    "                cluster = kmeans_fwperc[ img ]\n",
    "                if cluster == 0:\n",
    "                    classifierObject.setCluster(kmeans_fwperc_2[img])\n",
    "                else:\n",
    "                    classifierObject.setCluster(cluster)\n",
    "            else:\n",
    "                classifierObject.setCluster(4)\n",
    "\n",
    "    def __isClusteringAlreadyDone( self, canolaTimelapseImages ):\n",
    "        clusters = [k.getClassifierObject().getCluster() for k in canolaTimelapseImages]\n",
    "        return not np.any( np.equal( clusters, None ) )\n",
    "\n",
    "    def __kmeans( self, km_points_orig, nClusters ):\n",
    "        assert isinstance(km_points_orig, dict)\n",
    "        assert isinstance(nClusters, int) and nClusters > 1\n",
    "\n",
    "        km = skKMeans(n_clusters=nClusters)\n",
    "\n",
    "        # Get the ordered set of points (i.e. flower pixel percentages of each image)\n",
    "        km_points = np.array([k[1] for k in sorted(km_points_orig.items(), key=operator.itemgetter(1))]).reshape((-1, 1))\n",
    "                \n",
    "        # Compute KMeans\n",
    "        km.fit(km_points)\n",
    "\n",
    "        # Get the centroids ordered\n",
    "        km_centroids = list(km.cluster_centers_)        \n",
    "        km_centroids.sort()\n",
    "        \n",
    "        # Assign each image to a cluster\n",
    "        final_img_clusters = {}\n",
    "        for k, v in km_points_orig.items():\n",
    "            # Compute distance to each of the centroids\n",
    "            dist = np.array([abs(v - q) for q in km_centroids])\n",
    "\n",
    "            # Get the closest centroid\n",
    "            final_img_clusters[k] = int(dist.argmin())\n",
    "\n",
    "        return final_img_clusters\n",
    "\n",
    "    def __calculateNumberOfFlowerPixels(self, canolaTimelapseImages):\n",
    "        fileToFlowerPixelsDict = {}\n",
    "        for img in canolaTimelapseImages:\n",
    "            histObject = img.getHistogramObject()\n",
    "            hist_b = histObject.getHistogramB()\n",
    "            hist_b_shift = histObject.getHistogramBShift()\n",
    "            threshold = ( 155 + hist_b_shift ) % 256\n",
    "            n_flower_pixels = np.sum(hist_b[threshold:])\n",
    "            img.getClassifierObject().setNumberOfYellowPixels( n_flower_pixels )\n",
    "            fileToFlowerPixelsDict[ img ] = n_flower_pixels\n",
    "        return fileToFlowerPixelsDict\n",
    "\n",
    "\n",
    "class HistogramManager:\n",
    "    def runImages(self, canolaTimelapseImages):\n",
    "        if not self.__areHistogramsAlreadyComputed( canolaTimelapseImages ):\n",
    "            self.computeHistograms( canolaTimelapseImages )\n",
    "            self.computeHistogramShifts([ img.getHistogramObject() for img in canolaTimelapseImages ] )\n",
    "\n",
    "    def computeHistograms(self, canolaTimelapseImages):\n",
    "        \"\"\"\n",
    "        Compute the average A and B histograms over all images\n",
    "        \"\"\"\n",
    "        assert len(canolaTimelapseImages) > 0\n",
    "        histResult = dict(self.computeHistogramsOnSingleImage(image) for image in canolaTimelapseImages)\n",
    "\n",
    "        for img in canolaTimelapseImages:\n",
    "            histObject = img.getHistogramObject()\n",
    "            path = img.getPath()\n",
    "            histObject.setHistogramB( histResult[path]['histogramB'] )\n",
    "            histObject.setHistogramG( histResult[path]['histogramG'] )\n",
    "\n",
    "    def computeHistogramsOnSingleImage( self, canolaTimelapseImage ):\n",
    "        plotMask = canolaTimelapseImage.getPlotMask()\n",
    "        im_bgr = canolaTimelapseImage.readImage()\n",
    "        im_gray = cv2.cvtColor(im_bgr, cv2.COLOR_BGR2GRAY)\n",
    "        im_lab_plot = cv2.cvtColor(im_bgr, cv2.COLOR_BGR2Lab)\n",
    "        im_gray = im_gray[plotMask > 0]\n",
    "        im_lab_plot = im_lab_plot[plotMask > 0]\n",
    "        hist_G, _ = np.histogram(im_gray, 256, [0, 256])\n",
    "        hist_b, _ = np.histogram(im_lab_plot[:, 2], 256, [0, 256])\n",
    "        \n",
    "        return (canolaTimelapseImage.getPath(),{'histogramB' : hist_b,'histogramG' : hist_G})\n",
    "\n",
    "    def computeHistogramShifts(self, histogramObjects):\n",
    "        refHistObject = histogramObjects[0]\n",
    "        refHist = refHistObject.getHistogramB()\n",
    "        allHistsDict = {refHistObject : 0}\n",
    "            \n",
    "        for histObject in histogramObjects[1:]:\n",
    "            correlation_b = np.correlate(histObject.getHistogramB(), refHist, \"full\")\n",
    "            x_shift_b = correlation_b.argmax().astype( np.int8 )\n",
    "            allHistsDict[histObject] = x_shift_b\n",
    "\n",
    "        allHistograms = [k.getHistogramB() for k in histogramObjects]\n",
    "        correlation_reference = np.correlate(refHist,np.average( allHistograms, axis=0),\"full\")        \n",
    "        additionalShift = correlation_reference.argmax().astype(np.uint8)\n",
    "        \n",
    "        for histObject in histogramObjects:\n",
    "            histObject.setHistogramBShift(allHistsDict[histObject] + additionalShift )\n",
    "\n",
    "    def __areHistogramsAlreadyComputed( self, canolaTimelapseImages ):\n",
    "        histShifts = [k.getHistogramObject().getHistogramBShift() for k in canolaTimelapseImages]\n",
    "        return not np.any( np.equal( histShifts, None ) )\n",
    "\n",
    "\n",
    "class CorruptedImagesDetector:\n",
    "\n",
    "    def flagCorruptedImages(self, canolaTimelapseImages):\n",
    "        assert len( canolaTimelapseImages ) > 0\n",
    "        for img in canolaTimelapseImages:\n",
    "            hist_g = img.getHistogramObject().getHistogramG()\n",
    "            if max( hist_g ) / np.sum( hist_g ) >= 0.2:\n",
    "                img.getClassifierObject().flagCorrupted()\n",
    "\n",
    "\n",
    "class Mask:\n",
    "    @staticmethod\n",
    "    def generate( imageShape, boundCorners ):\n",
    "        if len( imageShape ) == 3:\n",
    "            modShape = imageShape[:-1]\n",
    "        else:\n",
    "            modShape = imageShape\n",
    "\n",
    "        def __crossProduct( p1, p2, p3 ):\n",
    "            v1 = [p2[0] - p1[0], p2[1] - p1[1]]\n",
    "            v2 = [p3[0] - p2[0], p3[1] - p2[1]]\n",
    "            return v1[0] * v2[1] - v1[1] * v2[0]\n",
    "\n",
    "        mask = np.zeros( modShape )\n",
    "        minX = max( [min( [x[0] for x in boundCorners] ), 0] )\n",
    "        minY = max( [min( [y[1] for y in boundCorners] ), 0] )\n",
    "        maxX = min( max( [x[0] for x in boundCorners] ), modShape[1] )\n",
    "        maxY = min( max( [y[1] for y in boundCorners] ), modShape[0] )\n",
    "\n",
    "        # Iterate through the containing-square and eliminate points\n",
    "        # that are out of the ROI\n",
    "        for x in range( minX, maxX ):\n",
    "            for y in range( minY, maxY ):\n",
    "                h1 = __crossProduct( boundCorners[2], boundCorners[0], (x, y) )\n",
    "                h2 = __crossProduct( boundCorners[3], boundCorners[1], (x, y) )\n",
    "                v1 = __crossProduct( boundCorners[0], boundCorners[1], (x, y) )\n",
    "                v2 = __crossProduct( boundCorners[2], boundCorners[3], (x, y) )\n",
    "                if h1 > 0 > h2 and v1 > 0 > v2:\n",
    "                    mask[y, x] = 255\n",
    "        return mask\n",
    "\n",
    "    \n",
    "def findImagesLocally(imagesBasePath):\n",
    "\n",
    "    imgs = []\n",
    "\n",
    "    regionObject = CanolaPlotRegionObject()\n",
    "    regionObject.setPlot('1237')\n",
    "    regionObject.setCorners([(10, 10), (1270, 10), (10, 710), (1270, 710)])\n",
    "\n",
    "    imagesFullPath = glob.glob(imagesBasePath+'*.jpg')\n",
    "    \n",
    "    for imgPath in imagesFullPath:\n",
    "        img = CanolaTimelapseImage()\n",
    "        img.setPath(imgPath)\n",
    "        img.setRegionObject(regionObject)\n",
    "        img.setImageSize((720,1280))\n",
    "\n",
    "        imgs.append(img)\n",
    "    \n",
    "    return imgs\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    application_start_time = time()\n",
    "        \n",
    "    imagesBasePath = '/Users/habib/Desktop/still_images_small/'\n",
    "\n",
    "    canolaTimelapseImages = findImagesLocally(imagesBasePath)\n",
    "    \n",
    "    imageClassifier = ImageClassifier()\n",
    "    flowerCountImageProcessor = FlowerCountImageProcessor()\n",
    "\n",
    "    imageClassifier.classify(canolaTimelapseImages)\n",
    "    imagesOnClusterZero = [img for img in canolaTimelapseImages if img.getClassifierObject().getCluster() == 0]\n",
    "    sortedByYellowPixels = sorted(imagesOnClusterZero,key=lambda x: x.getClassifierObject().getNumberOfYellowPixels())\n",
    "    flowerCountImageProcessor.run(sortedByYellowPixels)\n",
    "\n",
    "    application_end_time = time() - application_start_time\n",
    "\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(\"SUCCESS: Images procesed in {} seconds\".format(round(application_end_time, 3)))\n",
    "    print(\"---------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sortedByYellowPixels[0].showDetectedBlobs()\n",
    "#len(sortedByYellowPixels[0].getFlowerCountObject().getBlobs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Original Author: Javier Garcia\n",
    "# Modified: Habib Sabiu\n",
    "# Date: August 24, 2017\n",
    "#\n",
    "# Description: A Spark application to detect and count canola flowers from still camera images.\n",
    "#              The script reads input images from a HDFS directory. The output is a text file\n",
    "#              containing the image file name and estimate of flower count. This file is saved to\n",
    "#              a specified HDFS directory\n",
    "#\n",
    "# Usage: spark-submit --master [spark master] --py-files [classes file] [file name] [input path] [output_path] [job name]\n",
    "#        [spark master] = Can be Spark's Standalone, Mesos, or YARN\n",
    "#        To run on:-\n",
    "#                 Standalone: spark://discus-p2irc-master:7077\n",
    "#                 Mesos: mesos://discus-p2irc-master:5050\n",
    "#                 YARN: yarn\n",
    "#        [classes file] = Full path to classes definitions (../canola_timelapse_image.py)\n",
    "#        [file name]    = Full path to the python script (../imageFlowerCounterNew.py)\n",
    "#        [input_path]   = Full HDFS path to input images\n",
    "#        [output_path]  = Full HDFS path to save results. Please note that all contents of this\n",
    "#                        folder will be deleted if it already exist\n",
    "#        [job_name]     = A nice name for the job. This will be displayed on the web UI\n",
    "#\n",
    "# Example usage: spark-submit --master spark://discus-p2irc-master:7077 --py-files canola_timelapse_image.py newImageFlowerCounter.py \\\n",
    "#                hdfs://discus-p2irc-master:54310/user/hduser/habib/still_camera_images/ \\\n",
    "#                hdfs://discus-p2irc-master:54310/user/hduser/habib/flower_counter_output/ imageFlowerCounter \n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import glob\n",
    "import pyspark\n",
    "import operator\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "\n",
    "from enum import Enum\n",
    "from time import time\n",
    "from io import StringIO, BytesIO\n",
    "from PIL import Image, ImageFile\n",
    "from skimage.feature import blob_doh\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from sklearn.cluster import KMeans as skKMeans\n",
    "\n",
    "from canola_timelapse_image import * \n",
    "\n",
    "\n",
    "\n",
    "class CanolaObject:\n",
    "    def __str__(self):\n",
    "        strObject = ''\n",
    "        for k, v in self.__dict__.items():\n",
    "            strObject += '{} : {}\\n'.format(k, v)\n",
    "        return strObject\n",
    "\n",
    "\n",
    "class CanolaPlotRegionObject(CanolaObject):\n",
    "    def __init__(self):\n",
    "        self.__id = None\n",
    "        self.__plot = None\n",
    "        self.__year = None\n",
    "        self.__corners = None\n",
    "        self.__allocatedPlotMask = None\n",
    "        self.__allocatedRegionMask = None\n",
    "\n",
    "    def setPlot(self, plot):\n",
    "        assert self.__plot is None\n",
    "        self.__plot = plot\n",
    "\n",
    "    def setYear(self, year):\n",
    "        assert self.__year is None\n",
    "        self.__year = year\n",
    "\n",
    "    def setCorners(self, corners):\n",
    "        assert self.__corners is None\n",
    "        self.__corners = corners\n",
    "\n",
    "    def setId(self, id):\n",
    "        assert self.__id is None\n",
    "        self.__id = id\n",
    "\n",
    "    def setPlotMask(self, plotMask):\n",
    "        assert self.__allocatedPlotMask is None\n",
    "        self.__allocatedPlotMask = plotMask\n",
    "\n",
    "    def setRegionMask(self, regionMask):\n",
    "        assert self.__allocatedRegionMask is None\n",
    "        self.__allocatedRegionMask = regionMask\n",
    "\n",
    "\n",
    "    def getPlot(self):\n",
    "        return self.__plot\n",
    "\n",
    "    def getYear(self):\n",
    "        return self.__year\n",
    "\n",
    "    def getCorners(self):\n",
    "        return self.__corners\n",
    "\n",
    "    def getId(self):\n",
    "        return self.__id\n",
    "\n",
    "    def getPlotMask(self):\n",
    "        return self.__allocatedPlotMask\n",
    "\n",
    "    def getRegionMask(self):\n",
    "        return self.__allocatedRegionMask\n",
    "\n",
    "\n",
    "class CanolaImageClassifierObject(CanolaObject):\n",
    "    def __init__(self):\n",
    "        self.__id = None\n",
    "        self.__imageId = None\n",
    "        self.__cluster = None\n",
    "        self.__numberOfYellowPixels = None\n",
    "        self.__corrupted = False\n",
    "        self.__regionObject = None\n",
    "\n",
    "    def setCluster(self, cluster):\n",
    "        self.__cluster = cluster\n",
    "\n",
    "    def setRegionObject(self, regionObject):\n",
    "        self.__regionObject = regionObject\n",
    "\n",
    "    def setNumberOfYellowPixels(self, numberOfYellowPixels):\n",
    "        self.__numberOfYellowPixels = numberOfYellowPixels\n",
    "\n",
    "    def setId(self, id):\n",
    "        self.__id = id\n",
    "\n",
    "    def setImageId(self, imageId):\n",
    "        self.__imageId = imageId\n",
    "\n",
    "    def flagCorrupted(self):\n",
    "        self.__corrupted = True\n",
    "\n",
    "\n",
    "    def getCluster(self):\n",
    "        return self.__cluster\n",
    "\n",
    "    def getRegionObject(self):\n",
    "        return self.__regionObject\n",
    "\n",
    "    def getNumberOfYellowPixels(self):\n",
    "        return self.__numberOfYellowPixels\n",
    "\n",
    "    def getId(self):\n",
    "        return self.__id\n",
    "\n",
    "    def getImageId(self):\n",
    "        return self.__imageId\n",
    "\n",
    "    def isCorrupted(self):\n",
    "        return self.__corrupted\n",
    "\n",
    "\n",
    "class HistogramObject(CanolaObject):\n",
    "    def __init__(self):\n",
    "        self.__id = None\n",
    "        self.__imageId = None\n",
    "        self.__histogramB = None\n",
    "        self.__histogramG = None\n",
    "        self.__histogramBShift = None\n",
    "        self.__regionObject = None\n",
    "\n",
    "    def setId(self, id):\n",
    "        assert self.__id is None\n",
    "        self.__id = id\n",
    "\n",
    "    def setImageId(self, imageId):\n",
    "        assert self.__imageId is None\n",
    "        self.__imageId = imageId\n",
    "\n",
    "    def setHistogramB(self, histogramB):\n",
    "        assert self.__histogramB is None\n",
    "        self.__histogramB = histogramB\n",
    "\n",
    "    def setHistogramG(self, histogramG):\n",
    "        assert self.__histogramG is None\n",
    "        self.__histogramG = histogramG\n",
    "\n",
    "    def setHistogramBShift(self, histogramBShift):\n",
    "        assert self.__histogramBShift is None\n",
    "        self.__histogramBShift = histogramBShift\n",
    "\n",
    "    def setRegionObject(self, regionObject):\n",
    "        assert self.__regionObject is None\n",
    "        self.__regionObject = regionObject\n",
    "\n",
    "\n",
    "    def getId(self):\n",
    "        return self.__id\n",
    "\n",
    "    def getImageId(self):\n",
    "        return self.__imageId\n",
    "\n",
    "    def getHistogramB(self):\n",
    "        return self.__histogramB\n",
    "\n",
    "    def getHistogramG(self):\n",
    "        return self.__histogramG\n",
    "\n",
    "    def getHistogramBShift(self):\n",
    "        return self.__histogramBShift\n",
    "\n",
    "    def getRegionObject(self):\n",
    "        return self.__regionObject\n",
    "\n",
    "\n",
    "class PipelineObject(CanolaObject):\n",
    "    def __init__(self, pipeline=None):\n",
    "        self.__id = None\n",
    "        self.__pipeline = pipeline\n",
    "\n",
    "    def setPipeline(self, pipeline):\n",
    "        assert self.__pipeline is None\n",
    "        self.__pipeline = pipeline\n",
    "\n",
    "    def setId(self, id):\n",
    "        assert self.__id is None\n",
    "        self.__id = id\n",
    "\n",
    "\n",
    "    def getPipeline(self):\n",
    "        return self.__pipeline\n",
    "\n",
    "    def getId(self):\n",
    "        return self.__id\n",
    "\n",
    "\n",
    "class FlowerCountObject(CanolaObject):\n",
    "    def __init__(self):\n",
    "        self.__id = None\n",
    "        self.__imageId = None\n",
    "        self.__blobs = None\n",
    "        self.__regionObject = None\n",
    "        self.__pipelineObject = PipelineObject(CanolaObject)\n",
    "\n",
    "    def setBlobs(self, blobs):\n",
    "        assert self.__blobs is None\n",
    "        self.__blobs = blobs\n",
    "\n",
    "    def setRegionObject(self, regionObject):\n",
    "        assert self.__regionObject is None\n",
    "        self.__regionObject = regionObject\n",
    "\n",
    "    def setId(self, id):\n",
    "        assert self.__id is None\n",
    "        self.__id = id\n",
    "\n",
    "    def setImageId(self, imageId):\n",
    "        assert self.__imageId is None\n",
    "        self.__imageId = imageId\n",
    "\n",
    "\n",
    "    def getPipelineObject(self):\n",
    "        return self.__pipelineObject\n",
    "\n",
    "    def getBlobs(self):\n",
    "        return self.__blobs\n",
    "\n",
    "    def getRegionObject(self):\n",
    "        return self.__regionObject\n",
    "\n",
    "    def getId(self):\n",
    "        return self.__id\n",
    "\n",
    "    def getImageId(self):\n",
    "        return self.__imageId\n",
    "\n",
    "\n",
    "class CanolaTimelapseImage(CanolaObject):\n",
    "    def __init__(self):\n",
    "        self.__id = None\n",
    "        self.__imageId = None\n",
    "        self.__path = None\n",
    "        self.__timestamp = None\n",
    "        self.__imageSize = None\n",
    "        self.__plot = None\n",
    "        self.__allocatedImageArray = None\n",
    "        self.__corrupted = False\n",
    "        self.__classifierObject = CanolaImageClassifierObject()\n",
    "        self.__histogramObject = HistogramObject()\n",
    "        self.__flowerCountObject = FlowerCountObject()\n",
    "\n",
    "    def readImage(self):\n",
    "        \"\"\"\n",
    "        if self.__allocatedImageArray is None:\n",
    "            ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "            pil_image = Image.open(self.__path).convert('RGB')\n",
    "            open_cv_image = np.array(pil_image)\n",
    "            self.__allocatedImageArray = open_cv_image[:, :, ::-1].copy()\n",
    "        \"\"\"\n",
    "        return self.__allocatedImageArray\n",
    "\n",
    "    def showDetectedBlobs(self):\n",
    "        blobs = self.__flowerCountObject.getBlobs()\n",
    "        assert blobs is not None\n",
    "        img = np.copy( self.readImage() )\n",
    "        for x, y, r in blobs:\n",
    "            cv2.circle(img,center=(int(y), int(x)),radius=int(r),color=(0, 255, 255),thickness=2)\n",
    "        cv2.imshow(\"{} {}\".format( self.__plot, self.__timestamp ),img )\n",
    "        cv2.waitKey( 0 )\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def getPlotMask(self):\n",
    "        regionObject = self.getRegionObject()\n",
    "        plotMask = regionObject.getPlotMask()\n",
    "\n",
    "        if plotMask is None:\n",
    "            regionObject.setPlotMask(Mask.generate(self.__imageSize,regionObject.getCorners()))\n",
    "        return regionObject.getPlotMask()\n",
    "\n",
    "    def getRegionMask(self):\n",
    "        regionObject = self.getRegionObject()\n",
    "        regionMask = regionObject.getRegionMask()\n",
    "        if regionMask is None:\n",
    "            regionManager = RegionManager()\n",
    "            regionObject.setRegionMask(regionManager.getRegionMask(self.__imageSize,regionObject.getCorners()))\n",
    "        return regionObject.getRegionMask()\n",
    "\n",
    "    # SETTERS\n",
    "\n",
    "    # I added this method for setting image data using Spark\n",
    "    def setImageArray(self, arrayData):\n",
    "        assert self.__allocatedImageArray is None\n",
    "        self.__allocatedImageArray = arrayData       \n",
    "\n",
    "    def setPath(self, path):\n",
    "        assert self.__path is None\n",
    "        self.__path = path\n",
    "\n",
    "    def setTimestamp(self, timestamp):\n",
    "        assert self.__timestamp is None\n",
    "        if isinstance( timestamp, str ):\n",
    "            timestamp = stringToDatetime( timestamp )\n",
    "        self.__timestamp = timestamp\n",
    "\n",
    "    def setImageId(self, imageId):\n",
    "        assert self.__imageId is None\n",
    "        self.__imageId = imageId\n",
    "        self.__classifierObject.setImageId( imageId )\n",
    "        self.__histogramObject.setImageId( imageId )\n",
    "        self.__flowerCountObject.setImageId( imageId )\n",
    "\n",
    "    def setImageSize(self, imageSize):\n",
    "        assert self.__imageSize is None\n",
    "        if isinstance( imageSize, str ):\n",
    "            imageSize = tuple([int(k) for k in imageSize.split('x')[::-1]])\n",
    "        self.__imageSize = imageSize\n",
    "\n",
    "    def setPlot(self, plot):\n",
    "        assert self.__plot is None\n",
    "        regionObject = self.getRegionObject()\n",
    "        if regionObject is not None:\n",
    "            regionPlot = regionObject.getPlot()\n",
    "            if regionPlot is not None:\n",
    "                assert plot == regionPlot\n",
    "        self.__plot = plot\n",
    "\n",
    "    def setId(self, id):\n",
    "        assert self.__id is None\n",
    "        self.__id = id\n",
    "\n",
    "    def setRegionObject(self, regionObject):\n",
    "        self.__classifierObject.setRegionObject( regionObject )\n",
    "        self.__histogramObject.setRegionObject( regionObject )\n",
    "        self.__flowerCountObject.setRegionObject( regionObject )\n",
    "\n",
    "\n",
    "    # GETTERS\n",
    "\n",
    "    def getPath(self):\n",
    "        return self.__path\n",
    "\n",
    "    def getTimestamp(self):\n",
    "        return self.__timestamp\n",
    "\n",
    "    def getImageId(self):\n",
    "        return self.__imageId\n",
    "\n",
    "    def getImageSize(self):\n",
    "        return self.__imageSize\n",
    "\n",
    "    def getPlot(self):\n",
    "        return self.__plot\n",
    "\n",
    "    def getRegionObject(self):\n",
    "        return self.__histogramObject.getRegionObject()\n",
    "\n",
    "    def getPipelineObject(self):\n",
    "        return self.__flowerCountObject.getPipelineObject()\n",
    "\n",
    "    def getClassifierObject(self):\n",
    "        return self.__classifierObject\n",
    "\n",
    "    def getHistogramObject(self):\n",
    "        return self.__histogramObject\n",
    "\n",
    "    def getFlowerCountObject(self):\n",
    "        return self.__flowerCountObject\n",
    "\n",
    "    def getId(self):\n",
    "        return self.__id\n",
    "\n",
    "    def isCorrupted(self):\n",
    "        return self.__classifierObject.isCorrupted()\n",
    "\n",
    "\n",
    "class ImageProcessingModule:\n",
    "\n",
    "    def processImage( self, imageArray, *argv ):\n",
    "        assert self._isValidImage(imageArray), self.__class__.__name__\n",
    "        return self._process( imageArray, *argv )\n",
    "\n",
    "    def getParamsFromCanolaTimelapseImage(self, canolaTimelapseImage):\n",
    "        return None\n",
    "\n",
    "    def _process( self, imageArray, *argv ):\n",
    "        pass\n",
    "\n",
    "    def _isValidImage(self, imageArray):\n",
    "        return isinstance( imageArray, np.ndarray ) and imageArray.dtype == np.uint8\n",
    "\n",
    "\n",
    "class ImageProcessingPipeline:\n",
    "    def __init__(self):\n",
    "        self.__modules = []\n",
    "\n",
    "    def addModule(self, moduleInstance):\n",
    "        assert isinstance( moduleInstance, ImageProcessingModule )\n",
    "        self.__modules.append( moduleInstance )\n",
    "\n",
    "    def run(self, canolaTimelapseImage):\n",
    "        res = canolaTimelapseImage.readImage()\n",
    "        for module in self.__modules:\n",
    "            res = module.processImage( res,module.getParamsFromCanolaTimelapseImage(canolaTimelapseImage ) )\n",
    "        return res\n",
    "\n",
    "    def __str__(self):\n",
    "        return ','.join([k.__class__.__name__ for k in self.__modules])\n",
    "\n",
    "\n",
    "class Transformation3D(ImageProcessingModule):\n",
    "    def _isValidImage(self, imageArray):\n",
    "        return ImageProcessingModule._isValidImage(self, imageArray) and np.ndim( imageArray ) == 3\n",
    "\n",
    "\n",
    "class Transformation2D(ImageProcessingModule):\n",
    "    def _isValidImage(self, imageArray):\n",
    "        return ImageProcessingModule._isValidImage(self, imageArray) and np.ndim( imageArray ) == 2\n",
    "\n",
    "\n",
    "class CIELabColorspaceModule(Transformation3D):\n",
    "    def _process( self, imageArray, *argv ):\n",
    "        \"\"\"\n",
    "        Shift image from BGR to CIELab colorspace and return channel B\n",
    "        \"\"\"\n",
    "        colorspace = cv2.cvtColor( imageArray, cv2.COLOR_BGR2Lab )\n",
    "        return colorspace[:,:,2]\n",
    "\n",
    "\n",
    "class OtsuThreshold(Transformation2D):\n",
    "    def _process( self, imageArray, *argv ):\n",
    "        \"\"\"\n",
    "        Apply Otsu threshold. Output image has zero on pixels with value\n",
    "        lower than threshold, and their original value otherwise\n",
    "        \"\"\"\n",
    "        blur = cv2.GaussianBlur( imageArray, (5,5), 0 )\n",
    "        return cv2.threshold( blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU )\n",
    "\n",
    "\n",
    "class SigmoidMapping(Transformation2D):\n",
    "    def getParamsFromCanolaTimelapseImage(self, canolaTimelapseImage):\n",
    "        return canolaTimelapseImage.getHistogramObject().getHistogramBShift()\n",
    "\n",
    "    def _process( self, imageArray, *argv ):\n",
    "        \"\"\"\n",
    "        Map every pixel's intensity to an output value given by a sigmoid function.\n",
    "        f(x) = K / ( 1 + e^(t-d*x) )\n",
    "        \"\"\"\n",
    "        yellowThreshMapValue = 0.99\n",
    "        yellowThreshFromZero = 6\n",
    "        yellowThreshold = 155\n",
    "\n",
    "        hist_b_shift = argv[0]\n",
    "        imageArrayFloat = np.array( imageArray, dtype=np.float32 )\n",
    "        t_exp = (yellowThreshold + hist_b_shift - yellowThreshFromZero) % 256\n",
    "        k_exp = np.log(1 / yellowThreshMapValue - 1) / yellowThreshFromZero\n",
    "        imgAsFloat = 1 / (1 + np.exp(k_exp * (imageArrayFloat - t_exp)))\n",
    "        return ( imgAsFloat * 255 ).astype( np.uint8 )\n",
    "\n",
    "\n",
    "class IntensityMapping(Transformation2D):\n",
    "    def getParamsFromCanolaTimelapseImage(self, canolaTimelapseImage):\n",
    "        return canolaTimelapseImage.getHistogramObject().getHistogramBShift()\n",
    "\n",
    "    def _process( self, imageArray, *argv ):\n",
    "        \"\"\"\n",
    "        Perform mapping on grayscale channel to highlight flowers\n",
    "        \"\"\"\n",
    "        hist_b_shift = argv[0]\n",
    "        imageArrayFloat = np.array( imageArray, dtype=np.float )\n",
    "        threshold = ( self._params[\"flowerIntensityThreshold\"] + hist_b_shift ) % 256\n",
    "        imageArrayFloat = np.clip( imageArrayFloat, 0, threshold + 10 )\n",
    "        imageArrayFloat -= threshold - 8\n",
    "        imageArrayFloat /= threshold + 10\n",
    "        imageArrayFloat = np.clip( imageArrayFloat, 0, 1 )\n",
    "        return np.array( imageArrayFloat, dtype=np.uint8 )\n",
    "\n",
    "\n",
    "class BlobDetection(Transformation2D):\n",
    "    def getParamsFromCanolaTimelapseImage(self, canolaTimelapseImage):\n",
    "        return [canolaTimelapseImage.getPlotMask(),canolaTimelapseImage.getClassifierObject().getNumberOfYellowPixels()]\n",
    "\n",
    "    def _process( self, imageArray, *argv ):\n",
    "        \"\"\"\n",
    "        Count blobs\n",
    "        :param *argv: Mask\n",
    "        :return: List of tuples with (x, y, size) information of every blob detected\n",
    "        \"\"\"\n",
    "        mask = argv[0][0]\n",
    "        yellowPixels = argv[0][1]\n",
    "        if yellowPixels == 0:\n",
    "            return []\n",
    "        mask = mask > 0\n",
    "        maskedImage = np.copy( imageArray )\n",
    "        maskedImage[ mask == 0 ] = 0\n",
    "        blobs = blob_doh(maskedImage,max_sigma=8,min_sigma=3 )\n",
    "        return [[int(x), int(y), float(z)] for x, y, z in blobs]\n",
    "\n",
    "\n",
    "class Mask:\n",
    "    @staticmethod\n",
    "    def generate( imageShape, boundCorners ):\n",
    "        if len( imageShape ) == 3:\n",
    "            modShape = imageShape[:-1]\n",
    "        else:\n",
    "            modShape = imageShape\n",
    "\n",
    "        def __crossProduct( p1, p2, p3 ):\n",
    "            v1 = [p2[0] - p1[0], p2[1] - p1[1]]\n",
    "            v2 = [p3[0] - p2[0], p3[1] - p2[1]]\n",
    "            return v1[0] * v2[1] - v1[1] * v2[0]\n",
    "\n",
    "        mask = np.zeros( modShape )\n",
    "        minX = max( [min( [x[0] for x in boundCorners] ), 0] )\n",
    "        minY = max( [min( [y[1] for y in boundCorners] ), 0] )\n",
    "        maxX = min( max( [x[0] for x in boundCorners] ), modShape[1] )\n",
    "        maxY = min( max( [y[1] for y in boundCorners] ), modShape[0] )\n",
    "\n",
    "        # Iterate through the containing-square and eliminate points\n",
    "        # that are out of the ROI\n",
    "        for x in range( minX, maxX ):\n",
    "            for y in range( minY, maxY ):\n",
    "                h1 = __crossProduct( boundCorners[2], boundCorners[0], (x, y) )\n",
    "                h2 = __crossProduct( boundCorners[3], boundCorners[1], (x, y) )\n",
    "                v1 = __crossProduct( boundCorners[0], boundCorners[1], (x, y) )\n",
    "                v2 = __crossProduct( boundCorners[2], boundCorners[3], (x, y) )\n",
    "                if h1 > 0 > h2 and v1 > 0 > v2:\n",
    "                    mask[y, x] = 255\n",
    "        return mask\n",
    "\n",
    "\n",
    "    \n",
    "def computeHistogramsOnSingleImage(canolaTimelapseImage):\n",
    "    plotMask = canolaTimelapseImage.getPlotMask()\n",
    "    im_bgr = canolaTimelapseImage.readImage()\n",
    "    im_gray = cv2.cvtColor(im_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    im_lab_plot = cv2.cvtColor(im_bgr, cv2.COLOR_BGR2Lab)\n",
    "    im_gray = im_gray[plotMask > 0]\n",
    "    im_lab_plot = im_lab_plot[plotMask > 0]\n",
    "    hist_G, _ = np.histogram(im_gray, 256, [0, 256])\n",
    "    hist_b, _ = np.histogram(im_lab_plot[:, 2], 256, [0, 256])\n",
    "\n",
    "    histObject = canolaTimelapseImage.getHistogramObject()\n",
    "    histObject.setHistogramB(hist_b)\n",
    "    histObject.setHistogramG(hist_G)\n",
    "\n",
    "    return canolaTimelapseImage\n",
    "\n",
    "\n",
    "def computeHistogramShifts(canolaTimelapseImages):\n",
    "\n",
    "    refHistObject = canolaTimelapseImages[0].getHistogramObject()\n",
    "    refHist = refHistObject.getHistogramB()\n",
    "\n",
    "    first_canolaTimelapseImage_rdd = sc.parallelize([canolaTimelapseImages[0]]) \\\n",
    "        .map(lambda x: {x: 0})\n",
    "\n",
    "    rest_canolaTimelapseImages_rdd = sc.parallelize(canolaTimelapseImages[1:]) \\\n",
    "        .map(lambda x: {x: (np.correlate(x.getHistogramObject().getHistogramB(), refHist, \"full\")).argmax().astype(np.int8)}) \n",
    "                                               \n",
    "    all_canolaTimelapseImage_rdd = first_canolaTimelapseImage_rdd.union(rest_canolaTimelapseImages_rdd)\n",
    "\n",
    "    average_histogram = sc.parallelize(canolaTimelapseImages) \\\n",
    "        .map(lambda x: x.getHistogramObject().getHistogramB()) \\\n",
    "        .reduce(lambda first_element, second_element: np.average([first_element + second_element], axis=0))\n",
    "\n",
    "    correlation_reference = np.correlate(refHist,average_histogram,\"full\")\n",
    "    additionalShift = correlation_reference.argmax().astype(np.uint8)\n",
    "    \n",
    "    histogramBShift_rdd = all_canolaTimelapseImage_rdd.map(lambda x: udpateHistogramBShift(x, additionalShift))\n",
    "\n",
    "    return histogramBShift_rdd\n",
    "\n",
    "\n",
    "def udpateHistogramBShift(canolaTimelapseImageDic, additionalShift):\n",
    "    key = next(iter(canolaTimelapseImageDic))\n",
    "    value = canolaTimelapseImageDic[key]\n",
    "    key.getHistogramObject().setHistogramBShift(value + additionalShift)\n",
    "    return key\n",
    "\n",
    "\n",
    "def CorruptedImagesDetector(canolaTimelapseImage):\n",
    "        \n",
    "    hist_g = canolaTimelapseImage.getHistogramObject().getHistogramG()\n",
    "    if max( hist_g ) / np.sum( hist_g ) >= 0.2:\n",
    "        canolaTimelapseImage.getClassifierObject().flagCorrupted()\n",
    "\n",
    "    return canolaTimelapseImage\n",
    "\n",
    "\n",
    "def calculateNumberOfFlowerPixels(canolaTimelapseImage):\n",
    "    \n",
    "    fileToFlowerPixelsDict = {}\n",
    "\n",
    "    histObject = canolaTimelapseImage.getHistogramObject()\n",
    "    hist_b = histObject.getHistogramB()\n",
    "    hist_b_shift = histObject.getHistogramBShift()\n",
    "    threshold = (155 + hist_b_shift) % 256\n",
    "    n_flower_pixels = np.sum(hist_b[threshold:])\n",
    "    canolaTimelapseImage.getClassifierObject().setNumberOfYellowPixels(n_flower_pixels)\n",
    "        \n",
    "    fileToFlowerPixelsDict[canolaTimelapseImage] = n_flower_pixels\n",
    "    \n",
    "    return fileToFlowerPixelsDict\n",
    "\n",
    "\n",
    "def fitKmeans(points, num_clusters):\n",
    "\n",
    "    km = skKMeans(n_clusters=num_clusters)\n",
    "\n",
    "    # Compute KMeans\n",
    "    km.fit(points)\n",
    "\n",
    "    # Get the centroids ordered\n",
    "    km_centroids = list(km.cluster_centers_)\n",
    "    km_centroids.sort()\n",
    "\n",
    "    return km_centroids\n",
    "\n",
    "\n",
    "def assignImagesToClusters(canolaTimelapseImage, km_centroids):\n",
    "\n",
    "    final_img_clusters = {}\n",
    "\n",
    "    key = next(iter(canolaTimelapseImage))\n",
    "    value = canolaTimelapseImage[key]\n",
    "\n",
    "    # Compute distance to each of the centroids\n",
    "    dist = np.array([abs(value - q) for q in km_centroids])\n",
    "\n",
    "    # Get the closest centroid\n",
    "    centroid = int(dist.argmin())\n",
    "\n",
    "    key.getClassifierObject().setCluster(centroid)\n",
    "\n",
    "    final_img_clusters[key] = value\n",
    "\n",
    "    return final_img_clusters\n",
    "\n",
    "\n",
    "def assignBlobs(canolaTimelapseImage):\n",
    "\n",
    "    blobs = flowerCountPipeline.run(canolaTimelapseImage)\n",
    "\n",
    "    canolaTimelapseImage.getFlowerCountObject().setBlobs(blobs)\n",
    "\n",
    "    return canolaTimelapseImage\n",
    "\n",
    "\n",
    "def read_images(image_rawdata):\n",
    "    \n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "    regionObject = CanolaPlotRegionObject()\n",
    "    regionObject.setPlot('1237')\n",
    "    regionObject.setCorners([(10, 10), (1270, 10), (10, 710), (1270, 710)])\n",
    "    \n",
    "    imgPath = image_rawdata[0]\n",
    "    imgData = np.array(io.imread(BytesIO(image_rawdata[1]))) \n",
    "    \n",
    "    img = CanolaTimelapseImage()\n",
    "    img.setPath(imgPath)\n",
    "    img.setRegionObject(regionObject)\n",
    "    img.setImageSize((720,1280))\n",
    "    img.setImageArray(imgData[:, :, ::-1].copy())\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    application_start_time = time()\n",
    "\n",
    "\n",
    "    #input_path = \"file:///Users/habib/Desktop/15072016_1108_images12/\"\n",
    "    input_path = \"file:///Users/habib/Desktop/still_images_small\"\n",
    "    output_path = \"file:///Users/habib/Desktop/outputs/\"\n",
    "    job_name = \"imageFlowerCounter\"\n",
    "\n",
    "    import shutil\n",
    "    if os.path.exists(output_path[7:]):\n",
    "        shutil.rmtree(output_path[7:])\n",
    "\n",
    "    \n",
    "    #input_path = sys.argv[1]\n",
    "    #output_path = sys.argv[2]\n",
    "    #job_name = sys.argv[3]\n",
    "\n",
    "    # Remove the output directory and all it contents if it already exist\n",
    "    #subprocess.call([\"hadoop\", \"fs\", \"-rm\", \"-r\", output_path])\n",
    "\n",
    "    flowerCountPipeline = ImageProcessingPipeline()\n",
    "    flowerCountPipeline.addModule(CIELabColorspaceModule())\n",
    "    flowerCountPipeline.addModule(SigmoidMapping())\n",
    "    flowerCountPipeline.addModule(BlobDetection())\n",
    "\n",
    "    sc = SparkContext(appName=job_name)\n",
    "    \n",
    "    raw_data_rdd = sc.binaryFiles(input_path)\n",
    "    \n",
    "    histResult_rdd = raw_data_rdd.map(read_images) \\\n",
    "        .map(lambda x: computeHistogramsOnSingleImage(x)) \n",
    "\n",
    "    refHist = histResult_rdd.first().getHistogramObject().getHistogramB()\n",
    "    \n",
    "    \"\"\"\n",
    "    # Averaging using reduce(): This is slightly slower and could result in out of memory error on large data\n",
    "    average_histogram = histResult_rdd.map(lambda x: x.getHistogramObject().getHistogramB()) \\\n",
    "        .reduce(lambda x, y: np.average([x + y], axis=0))\n",
    "    \"\"\"\n",
    "\n",
    "    # Averaging using aggregate()\n",
    "    seqOp = (lambda local_result, list_element: (local_result[0] + list_element, local_result[1] + 1) )\n",
    "    combOp = (lambda some_local_result, another_local_result: (some_local_result[0] + another_local_result[0], some_local_result[1] + another_local_result[1]))\n",
    "    aggregate = histResult_rdd.map(lambda x: x.getHistogramObject().getHistogramB()) \\\n",
    "        .aggregate( (0, 0), seqOp, combOp)\n",
    "    average_histogram = aggregate[0]/aggregate[1]\n",
    "\n",
    "    correlation_reference = np.correlate(refHist,average_histogram,\"full\")\n",
    "    additionalShift = correlation_reference.argmax().astype(np.uint8)\n",
    "    \n",
    "    histogramBShift_rdd = histResult_rdd.zipWithIndex() \\\n",
    "        .map(lambda x: {x[0]: 0} if x[1] == 0 else {x[0]: (np.correlate(x[0].getHistogramObject().getHistogramB(), refHist, \"full\")).argmax().astype(np.int8)}) \\\n",
    "        .map(lambda x: udpateHistogramBShift(x, additionalShift)) \\\n",
    "        .map(lambda x: CorruptedImagesDetector(x)) \\\n",
    "        .filter(lambda x: x.isCorrupted() == False) \\\n",
    "        .map(lambda x: calculateNumberOfFlowerPixels(x)) \\\n",
    "        .sortBy(lambda x: x[next(iter(x))]) \n",
    "\n",
    "    clustering_rdd_1 = histogramBShift_rdd.map(lambda x: [x[next(iter(x))]]) \n",
    "    cluster_centers_1 = fitKmeans(clustering_rdd_1, 4)\n",
    "\n",
    "    canolaImagesWithClusters_rdd = histogramBShift_rdd.map(lambda x: assignImagesToClusters(x, cluster_centers_1)) \\\n",
    "        .filter(lambda x: next(iter(x)).getClassifierObject().getCluster() == 0) \n",
    "\n",
    "    clustering_rdd_2 = canolaImagesWithClusters_rdd.map(lambda x: [x[next(iter(x))]]) \n",
    "    cluster_centers_2 = fitKmeans(clustering_rdd_2, 2)\n",
    "\n",
    "    processedCanolaImages_rdd = canolaImagesWithClusters_rdd.map(lambda x: assignImagesToClusters(x, cluster_centers_2)) \\\n",
    "        .map(lambda x: next(iter(x))) \\\n",
    "        .filter(lambda x: x.getClassifierObject().getCluster() == 0) \\\n",
    "        .sortBy(lambda x: x.getClassifierObject().getNumberOfYellowPixels()) \\\n",
    "        .map(lambda x: assignBlobs(x)) \\\n",
    "        .map(lambda x: (x.getPath(),len(x.getFlowerCountObject().getBlobs()))) \\\n",
    "        .coalesce(1, shuffle=True) \\\n",
    "        .saveAsTextFile(output_path)\n",
    "\n",
    "\n",
    "    application_end_time = time() - application_start_time\n",
    "\n",
    "    sc.stop()\n",
    "    \n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(\"SUCCESS: Images procesed in {} seconds\".format(round(application_end_time, 3)))\n",
    "    print(\"---------------------------------------------------\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.47206665  0.47206665  0.59296169]\n",
      " [ 0.43265745  0.43265745  0.42754646]\n",
      " [ 0.59078162  0.59078162  0.59329013]\n",
      " [ 0.47054758  0.47054758  0.30010388]\n",
      " [ 0.42392359  0.42392359  0.44286934]\n",
      " [ 0.39879656  0.39879656  0.36610327]\n",
      " [ 0.38529554  0.38529554  0.64768795]\n",
      " [ 0.47160984  0.47160984  0.47687432]\n",
      " [ 0.55114161  0.55114161  0.57399958]\n",
      " [ 0.51893213  0.51893213  0.32941311]\n",
      " [ 0.47088674  0.47088674  0.71051141]\n",
      " [ 0.5708172   0.5708172   0.76748609]\n",
      " [ 0.48012217  0.48012217  0.45938178]\n",
      " [ 0.51869393  0.51869393  0.46373232]\n",
      " [ 0.38125527  0.38125527  0.41838349]\n",
      " [ 0.65380819  0.65380819  0.80326801]\n",
      " [ 0.24323815  0.24323815  0.06745904]\n",
      " [ 0.4198887   0.4198887   0.55632412]\n",
      " [ 0.52512965  0.52512965  0.50441899]\n",
      " [ 0.41516079  0.41516079  0.27862258]\n",
      " [ 0.54880461  0.54880461  0.61731709]\n",
      " [ 0.54194504  0.54194504  0.40750671]\n",
      " [ 0.51365962  0.51365962  0.42546481]\n",
      " [ 0.52847504  0.52847504  0.42806507]\n",
      " [ 0.57267408  0.57267408  0.7646705 ]\n",
      " [ 0.42316975  0.42316975  0.43548606]\n",
      " [ 0.52844028  0.52844028  0.43443843]\n",
      " [ 0.63324896  0.63324896  0.69082181]\n",
      " [ 0.40841333  0.40841333  0.22315128]\n",
      " [ 0.58023348  0.58023348  0.35574779]\n",
      " [ 0.54228597  0.54228597  0.37290605]\n",
      " [ 0.59074998  0.59074998  0.38285501]\n",
      " [ 0.44698255  0.44698255  0.38479398]\n",
      " [ 0.78828593  0.78828593  0.74580608]\n",
      " [ 0.65018938  0.65018938  0.43865435]\n",
      " [ 0.42858643  0.42858643  0.20198346]\n",
      " [ 0.44816644  0.44816644  0.36271857]\n",
      " [ 0.51920676  0.51920676  0.48024719]\n",
      " [ 0.48522788  0.48522788  0.39086204]\n",
      " [ 0.46596905  0.46596905  0.48492001]\n",
      " [ 0.60162493  0.60162493  0.65963929]\n",
      " [ 0.54320997  0.54320997  0.61976991]\n",
      " [ 0.45304247  0.45304247  0.6287475 ]\n",
      " [ 0.39754917  0.39754917  0.33676785]\n",
      " [ 0.53272582  0.53272582  0.5172653 ]\n",
      " [ 0.59742498  0.59742498  0.56483247]\n",
      " [ 0.40571189  0.40571189  0.65316693]\n",
      " [ 0.50851133  0.50851133  0.55038878]\n",
      " [ 0.34933235  0.34933235  0.46572245]\n",
      " [ 0.5173255   0.5173255   0.50804749]\n",
      " [ 0.4216291   0.4216291   0.25243811]\n",
      " [ 0.56147627  0.56147627  0.57859879]\n",
      " [ 0.51937076  0.51937076  0.42952115]\n",
      " [ 0.39523335  0.39523335  0.48646428]\n",
      " [ 0.47943778  0.47943778  0.67109334]\n",
      " [ 0.58325733  0.58325733  0.61848581]\n",
      " [ 0.47116421  0.47116421  0.42332883]\n",
      " [ 0.48346942  0.48346942  0.49735936]\n",
      " [ 0.60156913  0.60156913  0.45282475]\n",
      " [ 0.59033769  0.59033769  0.57970816]\n",
      " [ 0.5799619   0.5799619   0.60365849]\n",
      " [ 0.53737702  0.53737702  0.5687214 ]\n",
      " [ 0.45493424  0.45493424  0.48119476]\n",
      " [ 0.34723563  0.34723563  0.70228517]\n",
      " [ 0.60216647  0.60216647  0.61020558]\n",
      " [ 0.42866839  0.42866839  0.52097435]\n",
      " [ 0.44603516  0.44603516  0.14490387]\n",
      " [ 0.60151787  0.60151787  0.63488539]\n",
      " [ 0.34577568  0.34577568  0.46331346]\n",
      " [ 0.36035913  0.36035913  0.3794268 ]\n",
      " [ 0.44064151  0.44064151  0.42579037]\n",
      " [ 0.42902541  0.42902541  0.58717814]\n",
      " [ 0.35431327  0.35431327  0.15852913]\n",
      " [ 0.62848668  0.62848668  0.65000676]\n",
      " [ 0.36172496  0.36172496  0.25136277]\n",
      " [ 0.48401572  0.48401572  0.33749626]\n",
      " [ 0.44416601  0.44416601  0.38518108]\n",
      " [ 0.72612946  0.72612946  0.57500442]\n",
      " [ 0.51160542  0.51160542  0.50874433]\n",
      " [ 0.5434505   0.5434505   0.57713557]\n",
      " [ 0.5755214   0.5755214   0.61615312]\n",
      " [ 0.44224106  0.44224106  0.65370366]\n",
      " [ 0.4868619   0.4868619   0.51215109]\n",
      " [ 0.44638698  0.44638698  0.32698571]\n",
      " [ 0.58434696  0.58434696  0.37185636]\n",
      " [ 0.40539517  0.40539517  0.23930987]\n",
      " [ 0.59444881  0.59444881  0.5823567 ]\n",
      " [ 0.53306576  0.53306576  0.30442545]\n",
      " [ 0.67768954  0.67768954  0.76339747]\n",
      " [ 0.56320186  0.56320186  0.61035648]\n",
      " [ 0.62496643  0.62496643  0.6932196 ]\n",
      " [ 0.44307083  0.44307083  0.33250847]\n",
      " [ 0.47807978  0.47807978  0.35564787]\n",
      " [ 0.44834733  0.44834733  0.32994685]\n",
      " [ 0.57148925  0.57148925  0.4500575 ]\n",
      " [ 0.42427669  0.42427669  0.30953541]\n",
      " [ 0.57359189  0.57359189  0.50120582]\n",
      " [ 0.59066271  0.59066271  0.79954568]\n",
      " [ 0.47949067  0.47949067  0.3338843 ]\n",
      " [ 0.55623208  0.55623208  0.72273597]\n",
      " [ 0.52007217  0.52007217  0.32784303]\n",
      " [ 0.63573455  0.63573455  0.54355256]\n",
      " [ 0.55739842  0.55739842  0.59671345]\n",
      " [ 0.5932584   0.5932584   0.58487974]\n",
      " [ 0.4795777   0.4795777   0.41965878]\n",
      " [ 0.45748295  0.45748295  0.55934211]\n",
      " [ 0.395926    0.395926    0.26450836]\n",
      " [ 0.57445183  0.57445183  0.80235571]\n",
      " [ 0.42221899  0.42221899  0.23756577]\n",
      " [ 0.69369029  0.69369029  0.67454188]\n",
      " [ 0.50835459  0.50835459  0.76340838]\n",
      " [ 0.48848107  0.48848107  0.56778833]\n",
      " [ 0.61882109  0.61882109  0.40511909]\n",
      " [ 0.58896446  0.58896446  0.82651012]\n",
      " [ 0.62517647  0.62517647  0.62946271]\n",
      " [ 0.44356482  0.44356482  0.31283882]\n",
      " [ 0.61826469  0.61826469  0.63871913]\n",
      " [ 0.35841596  0.35841596  0.42879712]\n",
      " [ 0.50194847  0.50194847  0.56149644]\n",
      " [ 0.66868066  0.66868066  0.72223047]\n",
      " [ 0.53799722  0.53799722  0.53822807]\n",
      " [ 0.59582413  0.59582413  0.77671148]\n",
      " [ 0.49898145  0.49898145  0.25733254]\n",
      " [ 0.42053859  0.42053859  0.29743982]\n",
      " [ 0.42066949  0.42066949  0.5638731 ]\n",
      " [ 0.45487918  0.45487918  0.46903617]\n",
      " [ 0.4619479   0.4619479   0.20144653]\n",
      " [ 0.64948185  0.64948185  0.69094972]\n",
      " [ 0.54230278  0.54230278  0.46100144]\n",
      " [ 0.51723562  0.51723562  0.69532319]\n",
      " [ 0.36779629  0.36779629  0.25312423]\n",
      " [ 0.45532895  0.45532895  0.44030924]\n",
      " [ 0.51484738  0.51484738  0.24394346]\n",
      " [ 0.4279524   0.4279524   0.6880801 ]\n",
      " [ 0.44934441  0.44934441  0.4756796 ]\n",
      " [ 0.40326573  0.40326573  0.30553704]\n",
      " [ 0.58407901  0.58407901  0.62551957]\n",
      " [ 0.44503288  0.44503288  0.66325958]\n",
      " [ 0.52665635  0.52665635  0.72875984]\n",
      " [ 0.46164832  0.46164832  0.51615222]\n",
      " [ 0.42000917  0.42000917  0.24711768]\n",
      " [ 0.50263994  0.50263994  0.42234607]\n",
      " [ 0.52602212  0.52602212  0.61651277]\n",
      " [ 0.4988738   0.4988738   0.55302074]\n",
      " [ 0.37450766  0.37450766  0.41134015]\n",
      " [ 0.58529665  0.58529665  0.70148738]\n",
      " [ 0.55841778  0.55841778  0.72722232]\n",
      " [ 0.4754817   0.4754817   0.8255531 ]\n",
      " [ 0.44396714  0.44396714  0.46479338]\n",
      " [ 0.58506672  0.58506672  0.54477325]\n",
      " [ 0.51785821  0.51785821  0.34751348]\n",
      " [ 0.54940792  0.54940792  0.39828469]\n",
      " [ 0.4800954   0.4800954   0.4564593 ]\n",
      " [ 0.51501612  0.51501612  0.32608627]\n",
      " [ 0.56497183  0.56497183  0.38210337]\n",
      " [ 0.42981133  0.42981133  0.22178125]\n",
      " [ 0.56220065  0.56220065  0.69103184]\n",
      " [ 0.2653182   0.2653182   0.21093402]\n",
      " [ 0.31280414  0.31280414  0.4396151 ]\n",
      " [ 0.60744029  0.60744029  0.43386205]\n",
      " [ 0.25053576  0.25053576  0.26661525]\n",
      " [ 0.58876618  0.58876618  0.61957375]\n",
      " [ 0.46458376  0.46458376  0.46963993]\n",
      " [ 0.47864987  0.47864987  0.27868905]\n",
      " [ 0.49663009  0.49663009  0.72286767]\n",
      " [ 0.44786097  0.44786097  0.31681203]\n",
      " [ 0.48269511  0.48269511  0.41141863]\n",
      " [ 0.64895345  0.64895345  0.60553018]\n",
      " [ 0.38574902  0.38574902  0.20438781]\n",
      " [ 0.465967    0.465967    0.33133054]\n",
      " [ 0.47939963  0.47939963  0.5878409 ]\n",
      " [ 0.40073715  0.40073715  0.41825632]\n",
      " [ 0.43622556  0.43622556  0.22312535]\n",
      " [ 0.45950334  0.45950334  0.58972017]\n",
      " [ 0.45101705  0.45101705  0.50642309]\n",
      " [ 0.38084813  0.38084813  0.54420892]\n",
      " [ 0.48557592  0.48557592  0.35229808]\n",
      " [ 0.49780301  0.49780301  0.70797221]\n",
      " [ 0.52662056  0.52662056  0.45299261]\n",
      " [ 0.68525921  0.68525921  0.69295855]\n",
      " [ 0.47974926  0.47974926  0.62183953]\n",
      " [ 0.55900713  0.55900713  0.68114209]\n",
      " [ 0.54765807  0.54765807  0.31011945]\n",
      " [ 0.43279931  0.43279931  0.46720923]\n",
      " [ 0.48359351  0.48359351  0.69648684]\n",
      " [ 0.61812296  0.61812296  0.71728807]\n",
      " [ 0.40350246  0.40350246  0.73350501]\n",
      " [ 0.50545428  0.50545428  0.49590854]\n",
      " [ 0.4363217   0.4363217   0.51940424]\n",
      " [ 0.47249394  0.47249394  0.50814664]\n",
      " [ 0.60013105  0.60013105  0.48570692]\n",
      " [ 0.4426139   0.4426139   0.51266314]\n",
      " [ 0.66746657  0.66746657  0.5762916 ]\n",
      " [ 0.61050935  0.61050935  0.62315844]\n",
      " [ 0.34809229  0.34809229  0.2310929 ]\n",
      " [ 0.56848178  0.56848178  0.49505861]\n",
      " [ 0.59125629  0.59125629  0.76126607]\n",
      " [ 0.43180756  0.43180756  0.49291783]\n",
      " [ 0.72327457  0.72327457  0.78671821]\n",
      " [ 0.4095618   0.4095618   0.32741293]\n",
      " [ 0.48092745  0.48092745  0.5506013 ]\n",
      " [ 0.45905951  0.45905951  0.37408201]\n",
      " [ 0.43930829  0.43930829  0.29229143]\n",
      " [ 0.55427736  0.55427736  0.66674956]\n",
      " [ 0.51342079  0.51342079  0.5579103 ]\n",
      " [ 0.4930526   0.4930526   0.83249479]\n",
      " [ 0.61768021  0.61768021  0.58584103]\n",
      " [ 0.41741398  0.41741398  0.38907579]\n",
      " [ 0.52061643  0.52061643  0.80945623]\n",
      " [ 0.38164808  0.38164808  0.46628438]\n",
      " [ 0.65392131  0.65392131  0.56080573]\n",
      " [ 0.45135363  0.45135363  0.34496276]\n",
      " [ 0.46592724  0.46592724  0.34698092]\n",
      " [ 0.40046101  0.40046101  0.53474377]\n",
      " [ 0.53797686  0.53797686  0.57817671]\n",
      " [ 0.49919796  0.49919796  0.74794946]\n",
      " [ 0.40427447  0.40427447  0.41197078]\n",
      " [ 0.47459788  0.47459788  0.46673735]\n",
      " [ 0.42503246  0.42503246  0.39348022]\n",
      " [ 0.54486792  0.54486792  0.53638233]\n",
      " [ 0.6414773   0.6414773   0.41659566]\n",
      " [ 0.48385467  0.48385467  0.36627414]\n",
      " [ 0.62251982  0.62251982  0.67610437]\n",
      " [ 0.59843555  0.59843555  0.64539995]\n",
      " [ 0.55202759  0.55202759  0.71769936]\n",
      " [ 0.55744104  0.55744104  0.54987542]\n",
      " [ 0.49400085  0.49400085  0.77890843]\n",
      " [ 0.51916407  0.51916407  0.49369864]\n",
      " [ 0.4794499   0.4794499   0.47901319]\n",
      " [ 0.44020782  0.44020782  0.50872961]\n",
      " [ 0.63133459  0.63133459  0.33236556]\n",
      " [ 0.62169355  0.62169355  0.3911108 ]\n",
      " [ 0.53693918  0.53693918  0.58898383]\n",
      " [ 0.61764684  0.61764684  0.40896011]\n",
      " [ 0.60080976  0.60080976  0.4683563 ]\n",
      " [ 0.53612686  0.53612686  0.5389011 ]\n",
      " [ 0.55423049  0.55423049  0.69597964]\n",
      " [ 0.51157288  0.51157288  0.24302032]\n",
      " [ 0.40113732  0.40113732  0.48709168]\n",
      " [ 0.56590831  0.56590831  0.5350868 ]\n",
      " [ 0.50826563  0.50826563  0.74078945]\n",
      " [ 0.58405471  0.58405471  0.70852944]\n",
      " [ 0.52864422  0.52864422  0.77978686]\n",
      " [ 0.68337187  0.68337187  0.72862028]\n",
      " [ 0.42909987  0.42909987  0.17070444]\n",
      " [ 0.45967812  0.45967812  0.6526095 ]\n",
      " [ 0.62121132  0.62121132  0.7324923 ]\n",
      " [ 0.47639694  0.47639694  0.54088987]\n",
      " [ 0.40026683  0.40026683  0.75361379]\n",
      " [ 0.53447651  0.53447651  0.64118196]\n",
      " [ 0.56980942  0.56980942  0.65385532]\n",
      " [ 0.47817139  0.47817139  0.40278379]\n",
      " [ 0.70113028  0.70113028  0.51755988]\n",
      " [ 0.3214315   0.3214315   0.37987449]\n",
      " [ 0.57310269  0.57310269  0.60260884]\n",
      " [ 0.5851641   0.5851641   0.73317226]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pyspark import SparkContext\n",
    "\n",
    "\n",
    "sc = SparkContext()\n",
    "\n",
    "zeros = np.zeros(256)\n",
    "random_data = np.random.rand(10, 256)\n",
    "\n",
    "#-----------------numpy array mean---------------------\n",
    "np_mean = np.average(random_data, axis=0)\n",
    "#------------------------------------------------------\n",
    "\n",
    "listRDD = sc.parallelize(random_data, 10)\n",
    "\n",
    "#----------------------Aggregate-----------------------\n",
    "seqOp = (lambda local_result, list_element: (local_result[0] + list_element, local_result[1] + 1) )\n",
    "combOp = (lambda some_local_result, another_local_result: (some_local_result[0] + another_local_result[0], some_local_result[1] + another_local_result[1]))\n",
    "aggregate = listRDD.aggregate( (0, 0), seqOp, combOp)\n",
    "agg_mean = aggregate[0]/aggregate[1]\n",
    "#------------------------------------------------------\n",
    "\n",
    "#----------------------Reduce--------------------------\n",
    "reduce_mean = listRDD.reduce(lambda x, y: np.average([x] + [y], axis=0))\n",
    "#------------------------------------------------------\n",
    "\n",
    "stacked = np.vstack((np_mean,agg_mean,reduce_mean)).T\n",
    "\n",
    "print(stacked)\n",
    "#print(listRDD.count(), np.array(listRDD.first()).shape)\n",
    "\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "xx = processedCanolaImages_rdd.collect()\n",
    "myFile = open(\"processed_object.pkl\", 'wb')\n",
    "pickle.dump(xx, myFile)\n",
    "myFile.close()\n",
    "    \n",
    "fr = open('processed_object.pkl', 'rb')\n",
    "canolaImage = pickle.load(fr)\n",
    "print(canolaImage[0].showDetectedBlobs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
